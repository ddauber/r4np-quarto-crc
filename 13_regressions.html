<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>R for Non-Programmers: A Guide for Social Scientists - 13&nbsp; Regression: Creating models to predict future observations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./14_mixed_methods.html" rel="next">
<link href="./12_power_analysis.html" rel="prev">
<link href="./r4np_icon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PF1VJZVM7C"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PF1VJZVM7C');
</script>
<!-- favicons -->
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="apple-touch-icon-60x60.png">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./13_regressions.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Regression: Creating models to predict future observations</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">R for Non-Programmers: A Guide for Social Scientists</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ddauber/r4np-quarto-crc" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_about_the_author.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the author</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_before_you_get_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title"><code>Readme.</code> before you get started</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_why_start_learning_a_programming_language.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Why learn a programming language as a non-programmer?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_setting_up_r_rstudio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Setting up <em>R</em> and RStudio</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_rstudio_interface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The RStudio Interface</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_r_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title"><em>R</em> Basics: The very fundamentals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_starting_r_projects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Starting your <em>R</em> projects</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_data_wrangling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Wrangling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_descriptive_statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Descriptive Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_sources_of_bias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Sources of bias: Sampling, outliers, normality and other ‘conundrums’</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_correlations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Correlations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_group_comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Comparing groups</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_power_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Power: You either have it or you don’t</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_regressions.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Regression: Creating models to predict future observations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_mixed_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Mixed-methods research: Analysing qualitative data in <em>R</em></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_next_steps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Where to go from here: The next steps in your <em>R</em> journey</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_epilogue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Epilogue</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99_appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-single-linear-regression" id="toc-sec-single-linear-regression" class="nav-link active" data-scroll-target="#sec-single-linear-regression"><span class="header-section-number">13.1</span> Single linear regression</a>
  <ul class="collapse">
  <li><a href="#sec-fitting-a-regression-model-by-hand" id="toc-sec-fitting-a-regression-model-by-hand" class="nav-link" data-scroll-target="#sec-fitting-a-regression-model-by-hand"><span class="header-section-number">13.1.1</span> Fitting a regression model by hand, i.e.&nbsp;trial and error</a></li>
  <li><a href="#sec-fitting-a-regression-model-computationally" id="toc-sec-fitting-a-regression-model-computationally" class="nav-link" data-scroll-target="#sec-fitting-a-regression-model-computationally"><span class="header-section-number">13.1.2</span> Fitting a regression model computationally</a></li>
  </ul></li>
  <li><a href="#sec-multiple-regression" id="toc-sec-multiple-regression" class="nav-link" data-scroll-target="#sec-multiple-regression"><span class="header-section-number">13.2</span> Multiple regression</a>
  <ul class="collapse">
  <li><a href="#sec-outliers-in-multiple-regressions" id="toc-sec-outliers-in-multiple-regressions" class="nav-link" data-scroll-target="#sec-outliers-in-multiple-regressions"><span class="header-section-number">13.2.1</span> Outliers in multiple regressions</a></li>
  <li><a href="#sec-standardised-beta-vs-unstandardised-beta" id="toc-sec-standardised-beta-vs-unstandardised-beta" class="nav-link" data-scroll-target="#sec-standardised-beta-vs-unstandardised-beta"><span class="header-section-number">13.2.2</span> Standardised beta (<span class="math inline">\(\beta\)</span>) vs.&nbsp;unstandardised beta (<span class="math inline">\(B\)</span>)</a></li>
  <li><a href="#sec-multicollinearity" id="toc-sec-multicollinearity" class="nav-link" data-scroll-target="#sec-multicollinearity"><span class="header-section-number">13.2.3</span> Multicollinearity: The dilemma of highly correlated independent variables</a></li>
  </ul></li>
  <li><a href="#sec-hierarchical-regression" id="toc-sec-hierarchical-regression" class="nav-link" data-scroll-target="#sec-hierarchical-regression"><span class="header-section-number">13.3</span> Hierarchical regression</a>
  <ul class="collapse">
  <li><a href="#sec-regressions-with-control-variables" id="toc-sec-regressions-with-control-variables" class="nav-link" data-scroll-target="#sec-regressions-with-control-variables"><span class="header-section-number">13.3.1</span> Regressions with control variables</a></li>
  <li><a href="#sec-moderated-regression" id="toc-sec-moderated-regression" class="nav-link" data-scroll-target="#sec-moderated-regression"><span class="header-section-number">13.3.2</span> Moderated regression</a></li>
  <li><a href="#sec-centering-predictors" id="toc-sec-centering-predictors" class="nav-link" data-scroll-target="#sec-centering-predictors"><span class="header-section-number">13.3.3</span> Centering predictors: Making <span class="math inline">\(\beta\)</span>s more interpretable</a></li>
  </ul></li>
  <li><a href="#sec-ols-alternatives" id="toc-sec-ols-alternatives" class="nav-link" data-scroll-target="#sec-ols-alternatives"><span class="header-section-number">13.4</span> Other regression models: Alternatives to OLS</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ddauber/r4np-quarto-crc/blob/main/13_regressions.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/ddauber/r4np-quarto-crc/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-regression" class="quarto-section-identifier"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Regression: Creating models to predict future observations</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Regressions are an exciting area of data analysis since it enables us to make very specific predictions, incorporating different variables simultaneously. As the name implies, regressions ‘regress’, i.e., draw on past observations to make predictions about future observations. Thus, any analysis incorporating a regression makes the implicit assumption that the past best explains the future.</p>
<p>I once heard someone refer to regressions as driving a car by looking at the rear-view mirror. As long as the road is straight, we will be able to navigate the car successfully. However, if there is a sudden turn, we might drive into the abyss. This makes it very clear when and how regressions can be helpful. Regressions are also a machine learning method, which falls under <em>models with supervised learning</em>. If you find machine learning fascinating, you might find the book <em>“Hands-on Machine Learning with R”</em> <span class="citation" data-cites="boehmke2019hands">(<a href="references.html#ref-boehmke2019hands" role="doc-biblioref">Boehmke and Greenwell 2019</a>)</span> very insightful and engaging.</p>
<p>In the following chapters, we will cover three common types of regressions, which are also known as <em>Ordinary Least Squares (OLS) regression</em> models:</p>
<ul>
<li><p>Single linear regression,</p></li>
<li><p>Multiple regression, and</p></li>
<li><p>Hierarchical regression, as a special type of multiple regression.</p></li>
</ul>
<p>These three types will allow you to perform any OLS regression you could imagine. We can further distinguish two approaches to modelling via regressions:</p>
<ul>
<li><p><em>Hypothesis testing</em>: A regression model is defined ex-ante.</p></li>
<li><p><em>Machine learning</em>: A model is developed based on empirical data.</p></li>
</ul>
<p>In the following chapters, we will slightly blur the lines between both approaches by making assumptions about relationships (hypothesising) and make informed decisions based on our data (exploring).</p>
<p>All our regressions will be performed using the <code>covid</code> dataset of the <code>r4np</code> package to investigate whether certain factors can predict COVID numbers in different countries. I felt this book would not have been complete without covering this topic. After all, I wrote this piece during the pandemic, and it likely will mark a darker chapter in human history.</p>
<section id="sec-single-linear-regression" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="sec-single-linear-regression"><span class="header-section-number">13.1</span> Single linear regression</h2>
<p>A single linear regression looks very similar to a correlation (see <a href="10_correlations.html" class="quarto-xref"><span>Chapter 10</span></a>), but it is different in that it defines which variable affects another variable, i.e.&nbsp;a directed relationship. I used the terms <em>dependent variable (DV)</em> and <em>independent variable (IV)</em> previously when comparing groups (see <a href="11_group_comparison.html" class="quarto-xref"><span>Chapter 11</span></a>), and we will use them here again. In group comparisons, the independent variable was usually a <code>factor</code>, but in regressions, we can use data that is not a categorical variable, i.e.&nbsp;<code>integer</code>, <code>double</code>, etc.</p>
<p>While I understand that mathematical equations can be confusing, they are fairly simple to understand with regressions. Also, when writing our models in <em>R</em>, we will continuously use a <code>formula</code> to specify our regression. Thus, it is advisable to understand them. For example, a single linear regression consists of one independent variable and one dependent variable:</p>
<div data-align="center">
<p><span class="math display">\[
DV = \beta_{0} + IV * \beta_{1} + error
\]</span></p>
</div>
<p>Beta (<span class="math inline">\(\beta\)</span>) represents the coefficient of the independent variable, i.e.&nbsp;how much a change in IV causes a change in DV. For example, a one-unit change in IV might mean that DV changes by two units of IV:</p>
<div id="single-linear-regression-example" data-align="center">
<p><span class="math display">\[
DV = \beta_0 + IV * 2 + error
\]</span></p>
</div>
<p>If we ignore <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(error\)</span> for a moment, we find that that if <span class="math inline">\(IV = 3\)</span>, our <span class="math inline">\(DV = 3*2 = 6\)</span>. Similarly, if <span class="math inline">\(IV = 5\)</span>, we find that <span class="math inline">\(DV = 10\)</span>, and so on. According to this model, DV will always be twice as large as IV.</p>
<p>You might be wondering what <span class="math inline">\(\beta_0\)</span> stands for. It indicates an offset for each value, also called the intercept. Thus, no matter which value we choose for IV, DV will always be <span class="math inline">\(\beta_0\)</span> different from IV. It is a constant in our model. This can be best explained by visualising a regression line. Pay particular attention to the expressions after <code>function(x)</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A: Two models with different beta(0)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="dv">0</span> <span class="sc">+</span> x <span class="sc">*</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="dv">1</span> <span class="sc">+</span> x <span class="sc">*</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_modern</span>()  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/beta-zero-beta-one-explained-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># B: Two models with the same beta(0), but different beta(1)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="dv">0</span> <span class="sc">+</span> x <span class="sc">*</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="dv">0</span> <span class="sc">+</span> x <span class="sc">*</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  see<span class="sc">::</span><span class="fu">theme_modern</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/beta-zer-beta-one-explained-diff-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Plot A shows two regressions where only <span class="math inline">\(\beta_0\)</span> differs, i.e.&nbsp;the intercept. On the other hand, plot B shows what happens if we change <span class="math inline">\(\beta_1\)</span>, i.e.&nbsp;the slope. The two models in plot B have the same intercept and, therefore, the same origin. However, the blue line ascends quicker than the red one because its <span class="math inline">\(\beta_1\)</span> is higher than for the red model.</p>
<p>Lastly, the <span class="math inline">\(error\)</span> component in the regression model refers to the deviation of data from these regression lines. Ideally, we want this value to be as small as possible.</p>
<section id="sec-fitting-a-regression-model-by-hand" class="level3" data-number="13.1.1">
<h3 data-number="13.1.1" class="anchored" data-anchor-id="sec-fitting-a-regression-model-by-hand"><span class="header-section-number">13.1.1</span> Fitting a regression model by hand, i.e.&nbsp;trial and error</h3>
<p>If everything so far sounds all awfully theoretical, let’s try to fit a regression model by hand. First, we need to consider what our model should be able to predict. Let’s say that the number of COVID-19 cases predicts the number of deaths due to COVID-19. Intuitively we would assume this should be a linear relationship because the more cases there are, the more likely we find more deaths caused by it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We only select most recent numbers, i.e. "2021-08-26"</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and countries which have COVID cases</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>covid_sample <span class="ot">&lt;-</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  covid <span class="sc">|&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(date_reported <span class="sc">==</span> <span class="st">"2021-08-26"</span> <span class="sc">&amp;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>           cumulative_cases <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>covid_sample <span class="sc">|&gt;</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> cumulative_cases,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> cumulative_deaths)) <span class="sc">+</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/fitting-model-by-hand-step-one-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This data visualisation does not show us much. For example, we can see three countries, which appear to have considerably more cases than most other countries. Thus, all other countries are crammed together in the bottom left corner. To improve this visualisation without removing the outliers, we can rescale the x- and y-axis using the function <code>scale_x_continuous()</code> and <code>scale_y_continuous()</code> and apply a <code>"log"</code> transformation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>covid_sample <span class="sc">|&gt;</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> cumulative_cases,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> cumulative_deaths)) <span class="sc">+</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">trans =</span> <span class="st">"log"</span>) <span class="sc">+</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">trans =</span> <span class="st">"log"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/fitting-model-by-hand-step-two-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As a result, the scatterplot is now easier to read, and the dots are more spread out. This reveals that there is quite a strong relationship between <code>cumulative_cases</code> and <code>cumulative_deaths</code>. However, similar to before, we should avoid outliers when performing our analysis. For the sake of simplicity, I will limit the number of countries included in our analysis, which also removes the requirement of using <code>scale_x_continuous()</code> and <code>scale_y_continuous()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>covid_sample <span class="ot">&lt;-</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  covid_sample <span class="sc">|&gt;</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(date_reported <span class="sc">==</span> <span class="st">"2021-08-26"</span> <span class="sc">&amp;</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>           cumulative_cases <span class="sc">&gt;=</span> <span class="dv">2500</span> <span class="sc">&amp;</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>           cumulative_cases <span class="sc">&lt;=</span> <span class="dv">150000</span> <span class="sc">&amp;</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>           cumulative_deaths <span class="sc">&lt;=</span> <span class="dv">3000</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plot <span class="ot">&lt;-</span> covid_sample <span class="sc">|&gt;</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> cumulative_cases,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> cumulative_deaths)) <span class="sc">+</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>plot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/fitting-model-by hand-step-three-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We can try to fit a straight line on top by adjusting the beta values through trial and error. This is effectively what we hope to achieve with a regression: the <span class="math inline">\(\beta\)</span> values, which best explain our data. Let’s start with the basic assumption of <span class="math inline">\(y = x\)</span> without specific <span class="math inline">\(\beta\)</span>s, i.e.&nbsp;they are <code>0</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>plot <span class="sc">+</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) x, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/fitting-model-by-hand-step-four-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>What we try to achieve is that the red line fits nicely inside the cloud of dots. Our simple model provides a very poor fit to our data points, because the dots are considerably below it. This makes sense because <span class="math inline">\(y = x\)</span> would imply that every COVID-19 case leads to a death, i.e.&nbsp;everyone with COVID did not survive. From our own experience, we know that this is luckily not true. Ideally, we want the line to be less steep. We can do this by adding a <span class="math inline">\(\beta_1\)</span> to our equation. Maybe only 2% of people who got COVID-19 might not have recovered, i.e.&nbsp;<span class="math inline">\(\beta_1 = 0.02\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plot <span class="sc">+</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fl">0.02</span> <span class="sc">*</span> x, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/fitting-model-by-hand-step-five-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This time the line looks much more aligned with our observations. However, one could argue that it might have to move a little to the right to cover the observations at the bottom better. Therefore, we should add a <span class="math inline">\(\beta_0\)</span> to our equation, e.g.&nbsp;<code>-50</code>. This moves the line to the right. I also adjusted <span class="math inline">\(\beta_1\)</span> ever so slightly to make it fit even better.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>plot <span class="sc">+</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="sc">-</span><span class="dv">50</span> <span class="sc">+</span> <span class="fl">0.015</span> <span class="sc">*</span> x, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/fitting-model-by-hand-step-six-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We finished creating our regression model. If we wanted to express it as a formula, we would write <span class="math inline">\(DV = -5 + 0.015 * IV\)</span>. We could use this model to predict how high COVID cases will likely be in other countries not included in our dataset.</p>
</section>
<section id="sec-fitting-a-regression-model-computationally" class="level3" data-number="13.1.2">
<h3 data-number="13.1.2" class="anchored" data-anchor-id="sec-fitting-a-regression-model-computationally"><span class="header-section-number">13.1.2</span> Fitting a regression model computationally</h3>
<p>Estimating a regression model by hand is not ideal and far from accurate. Instead, we would compute the <span class="math inline">\(\beta\)</span>s based on our observed data, i.e.&nbsp;<code>cumulative_cases</code> and <code>cumulative_deaths</code>. We can use the function <code>lm()</code> to achieve this. I also rounded (<code>round()</code>) all <code>numeric</code> values to two decimal places to make the output easier to read. We also use <code>tidy()</code> to retrieve a cleaner result from the computation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We define our model</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>m0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(cumulative_deaths <span class="sc">~</span> cumulative_cases, <span class="at">data =</span> covid_sample)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># We clean the output to make it easer to read</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>broom<span class="sc">::</span><span class="fu">tidy</span>(m0) <span class="sc">|&gt;</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.numeric),</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                round, <span class="dv">2</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>         )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: There was 1 warning in `mutate()`.
ℹ In argument: `across(where(is.numeric), round, 2)`.
Caused by warning:
! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.
Supply arguments directly to `.fns` through an anonymous function instead.

  # Previously
  across(a:b, mean, na.rm = TRUE)

  # Now
  across(a:b, \(x) mean(x, na.rm = TRUE))</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term             estimate std.error statistic p.value
  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 (Intercept)         88.1       70.5      1.25    0.21
2 cumulative_cases     0.01       0       10.7     0   </code></pre>
</div>
</div>
<p>We first might notice that the <code>p.value</code> indicates that the relationship between <code>cumulative death</code> and <code>cumulative_cases</code> is significant. Thus, we can conclude that countries with more COVID cases also suffer from higher numbers of people who do not recover successfully from it. However, you might be wondering where our <span class="math inline">\(\beta\)</span> scores are. They are found where it says <code>estimate</code>. The standard error (<code>std.error</code>) denotes the <code>error</code> we specified in the <a href="#single-linear-regression">previous equation</a>. In the first row, we get the <span class="math inline">\(\beta_0\)</span>, i.e.&nbsp;the intercept (88.10). This one is larger than what we estimated, i.e.&nbsp;<code>-50</code>. However, <span class="math inline">\(\beta_1\)</span> is 0.01, which means we have done a very good job guessing this estimate. Still, it becomes apparent that it is much easier to use the function <code>lm()</code> to estimate a model than ‘eyeballing’ it.</p>
<p>Let me also briefly explain what the function <code>mutate(across(where(is.numeric), round, 2))</code> does in our computation:</p>
<ul>
<li><p><code>mutate()</code> implies we are changing values of variables,</p></li>
<li><p><code>across()</code> indicates that whatever function is placed insight this function will be applied ‘across’ certain columns. We specified our columns with</p></li>
<li><p><code>where(is.numeric)</code>, which indicates that all columns should be selected if they are <code>numeric</code>.</p></li>
<li><p><code>round, 2</code> represents the function <code>round()</code> and is applied with the paramter <code>2</code> to round numbers to two decimal places.</p></li>
</ul>
<p>While this is might seem like a more advanced method of handling your data, it is good to get into the habit of writing more efficient code, because it tends to be less prone to errors.</p>
<p>Returning to our data, we can now visualise the computed model (in blue) and our guessed model (in red) in one plot and see the differences. The plot shows that both regression lines are fairly close to each other. Admittedly, it was relatively easy to fit this model by hand. However, it is much more difficult to do so when more than two variables are involved.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>plot <span class="sc">+</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="sc">-</span><span class="dv">50</span> <span class="sc">+</span> <span class="fl">0.015</span> <span class="sc">*</span> x, <span class="at">col =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fl">88.1</span> <span class="sc">+</span> <span class="fl">0.01</span> <span class="sc">*</span> x, <span class="at">col =</span> <span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/comparing-computed-vs-hand-fitted-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>With our final model computed, we also need to check its quality in terms of predictive power based on how well it can explain our observed data. We tested models before when we looked at confirmatory factor analyses for latent variables (see <a href="07_data_wrangling.html#sec-latent-constructs" class="quarto-xref"><span>Section 7.8</span></a>). This time we want to know how accurate our model is in explaining observed data and, therefore, how accurate it predicts future observations. The package <code>performance</code> offers a nice shortcut to compute many different indicators at once:</p>
<ul>
<li><p><code>check_model()</code>: Checks for linearity, homogeneity, collinearity and outliers</p></li>
<li><p><code>model_performance()</code>: Tests the quality of our model.</p></li>
</ul>
<p>For now, we are mainly interested in the performance of our model. So, we can compute it the following way:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">model_performance</span>(m0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Indices of model performance

AIC      |     AICc |      BIC |    R2 | R2 (adj.) |    RMSE |   Sigma
----------------------------------------------------------------------
1472.626 | 1472.887 | 1480.319 | 0.548 |     0.543 | 502.573 | 507.891</code></pre>
</div>
</div>
<p>We are presented with quite a number of performance indicators, and here is how to read them:</p>
<ul>
<li><p><code>AIC</code> stands for <em>Akaike Information Criterion,</em> and the lower the score, the better the model.</p></li>
<li><p><code>BIC</code> stands for <em>Bayesian Information Criterion,</em> and the lower the score, the better the model.</p></li>
<li><p><code>R2</code> stands for <em>R squared</em> (<span class="math inline">\(R^2\)</span>) and is also known as the coefficient of determination. It measures how much the independent variable can explain the variance in the dependent variable. In other words, the higher <span class="math inline">\(R^2\)</span>, the better is our model, because our model can explain more of the variance. <span class="math inline">\(R^2\)</span> falls between 0-1, where 1 would imply that our model can explain 100% of the variance in our sample. <span class="math inline">\(R^2\)</span> is also considered a <em>goodness-of-fit measure</em>.</p></li>
<li><p><code>R2 (adj.)</code> stands for <em>adjusted R squared</em>. The adjusted version of <span class="math inline">\(R^2\)</span> becomes essential if we have more than one predictor (i.e.&nbsp;multiple independent variables) in our regression. The adjustment of <span class="math inline">\(R^2\)</span> accounts for the number of independent variables in our model. Thus, we can compare different models, even though they might have different numbers of predictors. It is important to note that unadjusted <span class="math inline">\(R^2\)</span> will always increase if we add more predictors.</p></li>
<li><p><code>RMSE</code> stands for <em>Root Mean Square Error</em> and indicates how small or large the prediction error of the model is. Conceptually, it aims to measure the average deviations of values from our model when we attempt predictions. The lower its score, the better, i.e.&nbsp;a score of 0 would imply that our model perfectly fits the data, which is likely never the case in the field of Social Sciences. The <em>RMSE</em> is particularly useful when trying to compare models.</p></li>
<li><p><code>Sigma</code> stands for the standard deviation of our residuals (the difference between predicted and empirically observed values) and is a measure of prediction accuracy. <code>Sigma</code> is <em>‘a measure of the average distance each observation falls from its prediction from the model’</em> <span class="citation" data-cites="gelman2020regression">(<a href="references.html#ref-gelman2020regression" role="doc-biblioref">Gelman, Hill, and Vehtari 2020</a>)</span> (p.&nbsp;168).</p></li>
</ul>
<p>Many of these indices will become more relevant when we compare models. However, <span class="math inline">\(R^2\)</span> can also be meaningfully interpreted without a reference model. We know that the bigger <span class="math inline">\(R^2\)</span>, the better. In our case, it is <code>0.548</code>, which is very good considering that our model consists of only one predictor. It is not easy to interpret whether a particular <span class="math inline">\(R^2\)</span> value is good or bad. In our simple single linear regression, <span class="math inline">\(R^2\)</span> is literally <em>‘r squared’</em>, which we already know from correlations and their effect sizes (see <a href="10_correlations.html#tbl-effect-size-cohen" class="quarto-xref">Table&nbsp;<span>10.2</span></a>). Thus, if we take the square root of <span class="math inline">\(R^2\)</span> we can retrieve the correlation coefficient, i.e.&nbsp;<span class="math inline">\(r = \sqrt{R^2} = \sqrt{0.548} = 0.740\)</span>. According to <span class="citation" data-cites="cohen1988statistical">J. Cohen (<a href="references.html#ref-cohen1988statistical" role="doc-biblioref">1988</a>)</span>, this would count as a large effect size.</p>
<p>However, the situation is slightly more complicated for multiple regressions, and we cannot use Cohen’s reference table by taking the square root of <span class="math inline">\(R^2\)</span>. Still, the meaning of <span class="math inline">\(R^2\)</span> and its adjusted version remain the same for our model.</p>
<p>Once you have a model and it is reasonably accurate, you can start making predictions. This can be achieved by using our model object <code>m0</code> with the function <code>add_predictions()</code> from the <code>modelr</code> package. However, first, we should define a set of values for our independent variable, i.e.&nbsp;<code>cumulative_cases</code>, which we store in a tibble using the <code>tibble()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df_predict <span class="ot">&lt;-</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">cumulative_cases =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Make our predictions</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>df_predict <span class="sc">|&gt;</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  modelr<span class="sc">::</span><span class="fu">add_predictions</span>(m0) <span class="sc">|&gt;</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pred =</span> <span class="fu">round</span>(pred, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 2
  cumulative_cases  pred
             &lt;dbl&gt; &lt;dbl&gt;
1              100    90
2             1000   102
3            10000   232</code></pre>
</div>
</div>
<p>The predictions are stored in column <code>pred</code>. Therefore, we know how many deaths from COVID have to be expected based on our model for each value in our dataset.</p>
<p>Single linear regressions are simple and an excellent way to introduce novice users of <em>R</em> to modelling social phenomena. However, we hardly ever find that a single variable can explain enough variance to be a helpful model. Instead, we can most likely improve most of our single regression models by considering more variables and using a multiple regression technique.</p>
</section>
</section>
<section id="sec-multiple-regression" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="sec-multiple-regression"><span class="header-section-number">13.2</span> Multiple regression</h2>
<p>Multiple regressions expand single linear regressions by allowing us to add more variables. Maybe less surprising, computing a multiple regression is similar to a single regression in <em>R</em> because it requires the same function, i.e.&nbsp;<code>lm()</code>. However, we add more IVs. Therefore, the equation we used before needs to be modified slightly by adding more independent variables. Each of these variables will have its own <span class="math inline">\(\beta\)</span> value:</p>
<div data-align="center">
<p><span class="math display">\[
DV = \beta_{0} + IV_{1} * \beta_{1} + IV_{2} * \beta_{2} + ... + IV_{n} * \beta_{n} + error
\]</span></p>
</div>
<p>In the last section, we wanted to know how many people will likely not recover from COVID. However, it might be even more interesting to understand how we can predict new cases and prevent casualties from the outset. Since I live in the United Kingdom during the pandemic, I am curious whether specific COVID measures help reduce the number of new cases in this country. To keep it more interesting, I will also add Germany to the mix since it has shown to be very effective in handling the pandemic relative to other European countries. Of course, feel free to pick different countries (maybe the one you live in?) to follow along with my example. In <a href="#sec-moderated-regression" class="quarto-xref"><span>Section 13.3.2</span></a> it will become apparent why I chose two countries (#spoiler-alert).</p>
<p>First, we create a dataset that only contains information from the <code>United Kingdom</code> and <code>Germany</code><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, using <code>filter()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>covid_uk_ger <span class="ot">&lt;-</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  covid <span class="sc">|&gt;</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(iso3 <span class="sc">==</span> <span class="st">"GBR"</span> <span class="sc">|</span> iso3 <span class="sc">==</span> <span class="st">"DEU"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the next step, we might want to know how new cases are distributed over time. It is always good to inspect the dependent variable to get a feeling of how much variance there is in our data. Having a more extensive range of data values is ideal because the regression model will consider low and high values of the dependent variable instead of just high or low scores. If you find that your dependent variable shows minimal variance, your model will likely be <em>‘overfitted’</em>. An overfitted model can very well explain the sample data but performs poorly with a new dataset. This is, of course not desirable, because the value of creating a model is to predict future observations. Let’s plot the DV <code>new_cases</code> across time to see when and how many new COVID cases had to be reported for both countries together.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>covid_uk_ger <span class="sc">|&gt;</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> date_reported,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> new_cases)) <span class="sc">+</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/mr-plot-new-cases-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We can tell that there are different waves of new cases with very low and very high values. As such, we should find variables that help us explain when <code>new_cases</code> are high and when they are low. If you have hypotheses to test, you would already know which variables to include in your regression. However, we do not have a hypothesis based on our prior reading or other studies. Thus, we pick variables of interest that we suspect could help us with modelling new COVID cases. For example, we can be fairly confident that the number of new COVID cases should be lower if more safety measures are in place - assuming that they are effective and everyone adheres to them. The <code>covid</code> dataset includes such information evaluated by the <a href="https://covid19.who.int/info/" target="blank" title="WHO">WHO</a>, i.e.&nbsp;<code>masks</code>, <code>travel</code>, <code>gatherings</code>, <code>schools</code> and <code>movements</code>. Remember, you can always find out what these variables stand for by typing <code>?covid</code> into the console. A higher value for these variables indicates that there were more safety measures in place. Scores can range from <code>0</code> (i.e.&nbsp;no measures are in place) to <code>100</code> (i.e.&nbsp;all WHO measures are in place).</p>
<p>We can add multiple variables by using the <code>+</code> symbol in the <code>lm()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create our model</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>m0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(new_cases <span class="sc">~</span> masks <span class="sc">+</span> movements <span class="sc">+</span> gatherings <span class="sc">+</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>           schools <span class="sc">+</span> businesses <span class="sc">+</span> travel,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> covid_uk_ger)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the model specifications.</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># I always round the p.value since I</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># do not prefer the scientific notation</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>broom<span class="sc">::</span><span class="fu">tidy</span>(m0) <span class="sc">|&gt;</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p.value =</span> <span class="fu">round</span>(p.value, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 7 × 5
  term        estimate std.error statistic p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 (Intercept)  -2585.     745.       -3.47   0.001
2 masks          -14.8      9.18     -1.61   0.108
3 movements      -54.7     15.5      -3.52   0    
4 gatherings     -26.0     19.8      -1.31   0.191
5 schools        394.      29.7      13.2    0    
6 businesses      93.7     13.8       6.79   0    
7 travel          49.5      9.30      5.32   0    </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the quality of our model</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">model_performance</span>(m0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Indices of model performance

AIC       |      AICc |       BIC |    R2 | R2 (adj.) |      RMSE |     Sigma
-----------------------------------------------------------------------------
25277.622 | 25277.744 | 25318.262 | 0.233 |     0.229 | 10027.204 | 10056.877</code></pre>
</div>
</div>
<p>Overall (and purely subjectively judged), the model is not particularly great because even though we added so many variables, the <span class="math inline">\(adjusted \ R^2\)</span> is not particularly high, i.e.&nbsp;‘only’ <code>0.229</code>. As mentioned earlier, for multiple regression, it is better to look at <span class="math inline">\(adjusted \ R^2\)</span>, because it adjusts for the number of variables in our model and makes the comparison of different models easier. There are a couple more important insights gained from this analysis:</p>
<ul>
<li><p>Not all variables appear to be significant. The predictors <code>masks</code> and <code>gatherings</code> are not significant, i.e.&nbsp;<code>p.value &gt; 0.05</code>. Thus, it might be worth removing these variables to optimise the model.</p></li>
<li><p>The variable, <code>movements</code> seems to reduce <code>new_cases</code>, i.e.&nbsp;it has a negative estimate (<span class="math inline">\(\beta\)</span>).</p></li>
<li><p>However, <code>schools</code>, <code>businesses</code>, and <code>travel</code> have a positive effect on <code>new_cases</code>.</p></li>
</ul>
<p>Especially the last point might appear confusing. How can it be that if more measures are taken, the number of new COVID cases increases? Should we avoid them? We have not considered in our regression that measures might be put in place to reduce the number of new cases rather than to prevent them. Thus, it might not be the case that <code>schools</code>, <code>businesses</code>, and <code>travel</code> predict higher <code>new_cases</code>, but rather the opposite, i.e.&nbsp;due to higher <code>new_cases</code>, the measures for <code>schools</code>, <code>businesses</code> and <code>travel</code> were tightened, which later on (with a time lag) led to lower <code>new_cases</code>. Thus, the relationships might be a bit more complicated, but to keep things simple, we accept that with our data, we face certain limitations (as is usually the case)<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>As a final step, we should remove the variables that are not significant and see how this affects our model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(new_cases <span class="sc">~</span> movements <span class="sc">+</span> schools <span class="sc">+</span> businesses <span class="sc">+</span> travel,</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> covid_uk_ger)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>broom<span class="sc">::</span><span class="fu">tidy</span>(m1) <span class="sc">|&gt;</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p.value =</span> <span class="fu">round</span>(p.value, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 5
  term        estimate std.error statistic p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 (Intercept)  -3024.     724.       -4.18       0
2 movements      -64.0     13.4      -4.79       0
3 schools        382.      28.8      13.3        0
4 businesses      90.5     12.9       7.01       0
5 travel          45.7      9.17      4.99       0</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the quality of our model</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">model_performance</span>(m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Indices of model performance

AIC       |      AICc |       BIC |    R2 | R2 (adj.) |      RMSE |     Sigma
-----------------------------------------------------------------------------
25279.519 | 25279.590 | 25309.999 | 0.229 |     0.227 | 10052.123 | 10073.343</code></pre>
</div>
</div>
<p>Comparing our original model <code>m0</code> with our revised model <code>m1</code>, we can see that our <code>R2 (adj.)</code> barely changed. Thus, <code>m1</code> is a superior model because it can explain (almost) the same amount of variance but with fewer predictors. The model <code>m1</code> would also be called a <em>parsimonious model</em>, i.e.&nbsp;a model that is simple but has good predictive power. When reading about multiple regressions, you might often hear people mention the <em>‘complexity’</em> of a model, which refers to the number of predictors. The complexity of a model is known as the <em>‘degrees of freedom (df) of the numerator’</em> and is computed as <span class="math inline">\(number\ of\ preditors - 1\)</span>. For example, in our model of 4 independent variables, the <em>df</em> of the numerator is 3. This value is relevant when computing the power of a regression model (see also <a href="12_power_analysis.html" class="quarto-xref"><span>Chapter 12</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">compare_performance</span>(m0, m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Comparison of Model Performance Indices

Name | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) |    R2 | R2 (adj.) |      RMSE |     Sigma
--------------------------------------------------------------------------------------------------------------
m0   |    lm | 25277.6 (0.721) | 25277.7 (0.716) | 25318.3 (0.016) | 0.233 |     0.229 | 10027.204 | 10056.877
m1   |    lm | 25279.5 (0.279) | 25279.6 (0.284) | 25310.0 (0.984) | 0.229 |     0.227 | 10052.123 | 10073.343</code></pre>
</div>
</div>
<p>However, there are a couple of things we overlooked when running this regression. If you are familiar with regressions already, you might have been folding your hands over your face and burst into tears about the blasphemous approach to linear regression modelling. Let me course-correct at this point.</p>
<p>Similar to other parametric approaches, we need to test for sources of bias, linearity, normality and homogeneity of variance. Since multiple regressions consider more than one variable, we must consider these criteria in light of other variables. As such, we have to draw on different tools to assess our data. There are certain pre- and post-tests we have to perform to evaluate and develop a multiple regression model fully:</p>
<ul>
<li><p><em>Pre-test</em>: We need to consider whether there are any outliers and whether all assumptions of OLS regression models are met.</p></li>
<li><p><em>Post-test</em>: We need to check whether our independent variables correlate very strongly with each other, i.e.&nbsp;are there issues of multiple collinearity.</p></li>
</ul>
<p>We already covered aspects of linearity, normality and homogeneity of variance. However, outliers and collinearity have to be reconsidered for multiple regressions.</p>
<section id="sec-outliers-in-multiple-regressions" class="level3" data-number="13.2.1">
<h3 data-number="13.2.1" class="anchored" data-anchor-id="sec-outliers-in-multiple-regressions"><span class="header-section-number">13.2.1</span> Outliers in multiple regressions</h3>
<p>While it should be fairly clear by now why we need to handle outliers (remember <a href="09_sources_of_bias.html#sec-dealing-with-outliers" class="quarto-xref"><span>Section 9.6</span></a>), our approach is somewhat different when we need to consider multiple variables at once. Instead of identifying outliers for each variable independently, we have to consider the interplay of variables. In other words, we need to find out how an outlier in our independent variable affects the overall model rather than just one other variable. Thus, we need a different technique to assess outliers. By now, you might not be shocked to find that there is more than one way of identifying outliers in regressions and that there are many different ways to compute them in <em>R</em>. <span class="citation" data-cites="cohen2014applied">(<a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>)</span> distinguishes between where one can find outliers in the model as summarised in <a href="#tbl-outliers-in-multiple-regressions" class="quarto-xref">Table&nbsp;<span>13.1</span></a>). I offer a selection of possible ways to compute the relevant statistics, but this list is not exhaustive. For example, many of these statistics can also be found using the function <code>influence.measures()</code>.</p>
<div id="tbl-outliers-in-multiple-regressions" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-outliers-in-multiple-regressions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;13.1: Outlier detection in multiple regressions
</figcaption>
<div aria-describedby="tbl-outliers-in-multiple-regressions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<colgroup>
<col style="width: 16%">
<col style="width: 25%">
<col style="width: 57%">
</colgroup>
<thead>
<tr class="header">
<th>Outlier in?</th>
<th>Measures</th>
<th>function in R</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Dependent variable</em></td>
<td><ul>
<li>Internally studentised residuals</li>
</ul></td>
<td><ul>
<li><code>rstandard()</code> or <code>fortify()</code></li>
</ul></td>
</tr>
<tr class="even">
<td><em>Dependent variable</em></td>
<td><ul>
<li>Externally studentised residuals</li>
</ul></td>
<td><ul>
<li><code>rstudent()</code></li>
</ul></td>
</tr>
<tr class="odd">
<td><em>Independent variable</em></td>
<td><ul>
<li>Leverage</li>
</ul></td>
<td><ul>
<li><code>hatvalues()</code> or <code>fortify()</code></li>
</ul></td>
</tr>
<tr class="even">
<td><em>Independent variable</em></td>
<td><ul>
<li>Mahalanobis distance</li>
</ul></td>
<td><ul>
<li><code>mahalanobis()</code><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> or <code>mahalanobis_distance()</code><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></li>
</ul></td>
</tr>
<tr class="odd">
<td><em>Entire model</em></td>
<td><p><em>Global measures of influence</em></p>
<ul>
<li><p>DFFITS,</p></li>
<li><p>Cook’s d</p></li>
</ul></td>
<td><p><em>Global measures of influence</em></p>
<ul>
<li><p><code>dffits()</code></p></li>
<li><p><code>cooks.distance()</code> or <code>fortify()</code></p></li>
</ul></td>
</tr>
<tr class="even">
<td><em>Entire model</em></td>
<td><p><em>Specific measures of influence:</em></p>
<ul>
<li>DFBETAS</li>
</ul></td>
<td><p><em>Specific measures of influence:</em></p>
<ul>
<li><code>dfbetas()</code></li>
</ul></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>While it might be clear why we need to use different approaches to find outliers in different model components, this might be less clear when evaluating outliers that affect the entire model. We distinguish between <em>global measures of influence</em>, which identify how a single observation affects the quality of the entire model, and <em>specific measures of influence</em>, which determine how a single observation affects each independent variable, i.e.&nbsp;its regression coefficients denoted as <span class="math inline">\(\beta\)</span>. It is recommended to look at all different outlier measures before venturing ahead to perform linear multiple regression. Going through the entire set of possible outliers would go way beyond the scope of this book. So, I will focus on five popular measures which cover all three categories:</p>
<ul>
<li><p>Dependent variable: Externally studentised residuals</p></li>
<li><p>Independent variable: Leverage and Mahalanobis distance</p></li>
<li><p>Entire model: Cook’s d and DFBETAS</p></li>
</ul>
<p>The approach taken is the same for the other outlier detection methods, but with different functions. Thus, it should be quite simple to reproduce these as well after having finished the chapters below.</p>
<section id="sec-outliers-in-the-dependent-variable" class="level4" data-number="13.2.1.1">
<h4 data-number="13.2.1.1" class="anchored" data-anchor-id="sec-outliers-in-the-dependent-variable"><span class="header-section-number">13.2.1.1</span> Outliers in the dependent variable</h4>
<p>Irrespective of whether we look at independent or dependent variables, we always want to know whether extreme values are present. Here I will use the externally studentised residual, which ’is the preferred statistic to use to identify cases whose (…) values are highly discrepant from their predicted values <span class="citation" data-cites="cohen2014applied">(<a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>)</span> (p.401).</p>
<p>First, we need to compute the residuals for our model as a new column in our dataset. Since we also want to use other methods to investigate outliers, we can use the function <code>fortify()</code>, which will add some of the later indicators and creates a <code>tibble</code> that only includes the variables from our model. This one handy function does a lot of things at once. In a second step, we add the studentised residuals using <code>rstudent()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tibble with some pre-computed stats</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>m1_outliers <span class="ot">&lt;-</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fortify</span>(m1) <span class="sc">|&gt;</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>()</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(m1_outliers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,188
Columns: 11
$ new_cases  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ movements  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ schools    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ businesses &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ travel     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ .hat       &lt;dbl&gt; 0.005159386, 0.005159386, 0.005159386, 0.005159386, 0.00515…
$ .sigma     &lt;dbl&gt; 10077.22, 10077.22, 10077.22, 10077.22, 10077.22, 10077.22,…
$ .cooksd    &lt;dbl&gt; 9.393496e-05, 9.393496e-05, 9.393496e-05, 9.393496e-05, 9.3…
$ .fitted    &lt;dbl&gt; -3023.617, -3023.617, -3023.617, -3023.617, -3023.617, -302…
$ .resid     &lt;dbl&gt; 3023.617, 3023.617, 3023.617, 3023.617, 3023.617, 3023.617,…
$ .stdresid  &lt;dbl&gt; 0.3009375, 0.3009375, 0.3009375, 0.3009375, 0.3009375, 0.30…</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the externally studentised residuals</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>m1_outliers <span class="ot">&lt;-</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  m1_outliers <span class="sc">|&gt;</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">.studresid =</span> <span class="fu">rstudent</span>(m1))</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(m1_outliers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,188
Columns: 12
$ new_cases  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ movements  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ schools    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ businesses &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ travel     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ .hat       &lt;dbl&gt; 0.005159386, 0.005159386, 0.005159386, 0.005159386, 0.00515…
$ .sigma     &lt;dbl&gt; 10077.22, 10077.22, 10077.22, 10077.22, 10077.22, 10077.22,…
$ .cooksd    &lt;dbl&gt; 9.393496e-05, 9.393496e-05, 9.393496e-05, 9.393496e-05, 9.3…
$ .fitted    &lt;dbl&gt; -3023.617, -3023.617, -3023.617, -3023.617, -3023.617, -302…
$ .resid     &lt;dbl&gt; 3023.617, 3023.617, 3023.617, 3023.617, 3023.617, 3023.617,…
$ .stdresid  &lt;dbl&gt; 0.3009375, 0.3009375, 0.3009375, 0.3009375, 0.3009375, 0.30…
$ .studresid &lt;dbl&gt; 0.3008218, 0.3008218, 0.3008218, 0.3008218, 0.3008218, 0.30…</code></pre>
</div>
</div>
<p>With our dataset ready for plotting, we can do exactly that and see which observations are particularly far away from the rest of our <code>.studresid</code> values. To plot each observation separately, we need an id variable for each row. We can quickly add one by using the function <code>rownames_to_column()</code>. This way, we can identify each column and also <code>filter()</code> out particular rows. You might be able to guess why this will come in handy at a later stage of our outlier analysis (hint: <a href="#sec-reviewing-the-outliers" class="quarto-xref"><span>Section 13.2.1.5</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an ID column</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>m1_outliers <span class="ot">&lt;-</span> m1_outliers <span class="sc">|&gt;</span> <span class="fu">rownames_to_column</span>()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>m1_outliers <span class="sc">|&gt;</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> rowname,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> .studresid)) <span class="sc">+</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/externally-studentised-residuals-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The values of the externally studentised residuals can be positive or negative. All we need to know is which values count as outliers and which ones do not. <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> (p.&nbsp;401) provides some guidance:</p>
<ul>
<li><p>general: <span class="math inline">\(outlier = \pm 2\)</span></p></li>
<li><p>bigger samples: <span class="math inline">\(outlier = \pm 3\)</span> or <span class="math inline">\(\pm 3.5\)</span> or <span class="math inline">\(\pm 4\)</span></p></li>
</ul>
<p>As you can tell, it is a matter of well-informed personal judgement. Our dataset consists of over 1200 observations. As such, the data frame certainly counts as large. We can take a look and see how many outliers we would get for each of the benchmarks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>out_detect <span class="ot">&lt;-</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  m1_outliers <span class="sc">|&gt;</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pm_2 =</span> <span class="fu">ifelse</span>(<span class="fu">abs</span>(.studresid) <span class="sc">&gt;</span> <span class="dv">2</span>, <span class="st">"TRUE"</span>, <span class="st">"FALSE"</span>),</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">pm_3 =</span> <span class="fu">ifelse</span>(<span class="fu">abs</span>(.studresid) <span class="sc">&gt;</span> <span class="dv">3</span>, <span class="st">"TRUE"</span>, <span class="st">"FALSE"</span>),</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">pm_35 =</span> <span class="fu">ifelse</span>(<span class="fu">abs</span>(.studresid) <span class="sc">&gt;</span> <span class="fl">3.5</span>, <span class="st">"TRUE"</span>, <span class="st">"FALSE"</span>),</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">pm_4 =</span> <span class="fu">ifelse</span>(<span class="fu">abs</span>(.studresid) <span class="sc">&gt;</span> <span class="dv">4</span>, <span class="st">"TRUE"</span>, <span class="st">"FALSE"</span>))</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>out_detect <span class="sc">|&gt;</span> <span class="fu">count</span>(pm_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  pm_2      n
  &lt;chr&gt; &lt;int&gt;
1 FALSE  1132
2 TRUE     56</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>out_detect <span class="sc">|&gt;</span> <span class="fu">count</span>(pm_3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  pm_3      n
  &lt;chr&gt; &lt;int&gt;
1 FALSE  1171
2 TRUE     17</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>out_detect <span class="sc">|&gt;</span> <span class="fu">count</span>(pm_35)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  pm_35     n
  &lt;chr&gt; &lt;int&gt;
1 FALSE  1173
2 TRUE     15</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>out_detect <span class="sc">|&gt;</span> <span class="fu">count</span>(pm_4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  pm_4      n
  &lt;chr&gt; &lt;int&gt;
1 FALSE  1179
2 TRUE      9</code></pre>
</div>
</div>
<p>The results indicate we could have as many as <code>56</code> outliers and as little as <code>9</code>. It becomes apparent that choosing the right threshold is a tricky undertaking. Let’s plot the data again to make it easier to read and add some of the thresholds. I skip <code>3.5</code> since it is very close to <code>3</code>. I also reorder the observations (i.e.&nbsp;the x-axis) based on <code>.studresid</code> using <code>reorder()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>m1_outliers <span class="sc">|&gt;</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(rowname, .studresid),</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> .studresid)) <span class="sc">+</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="st">"green"</span>) <span class="sc">+</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>), <span class="at">col =</span> <span class="st">"orange"</span>) <span class="sc">+</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/plot-outliers-ext-stud-resid-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>At this point, it is a matter of choosing the threshold that you feel is most appropriate. More importantly, though, you have to make sure you are transparent in your choices and provide some explanations around your decision-making. For example, a threshold of <code>2</code> appears too harsh for my taste and identifies too many observations as outliers. On the other hand, using the orange threshold of <code>3</code> seems to capture most observations I would consider an outlier because we can also visually see how the dots start to look less like a straight line and separate more strongly. Besides, <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> also suggests that a threshold of <code>3</code> is more suitable for larger datasets. Finally, since we have an ID column (i.e.&nbsp;<code>rownames</code>), we can also store our outliers in a separate object to easily reference them later for comparisons with other measures. Again, the purpose of doing this will become evident in <a href="#sec-reviewing-the-outliers" class="quarto-xref"><span>Section 13.2.1.5</span></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>outliers <span class="ot">&lt;-</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  out_detect <span class="sc">|&gt;</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(rowname, pm_3) <span class="sc">|&gt;</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">studresid =</span> pm_3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There are still more diagnostic steps we have to take before deciding which observations we want to remove or deal with in other ways (see also <a href="09_sources_of_bias.html#sec-dealing-with-outliers" class="quarto-xref"><span>Section 9.6</span></a>).</p>
</section>
<section id="sec-outliers-in-the-independent-variables" class="level4" data-number="13.2.1.2">
<h4 data-number="13.2.1.2" class="anchored" data-anchor-id="sec-outliers-in-the-independent-variables"><span class="header-section-number">13.2.1.2</span> Outliers in independent variables</h4>
<p>To identify outliers in independent variables, we can use <em>Leverage scores</em> or the <em>Mahalanobis distances</em>. Both are legitimate approaches and can be computed very easily.</p>
<p>For the leverage scores, we can find them already in our <code>fortify()</code>-ed dataset <code>m1_outliers</code>. They are in the column <code>.hat</code>. An outlier is defined by the distance from the average leverage value, i.e.&nbsp;the further the distance of an observation from this average leverage, the more likely we have to classify it as an outlier. The average leverage is computed as follows:</p>
<div id="average-leverage-equation" data-align="center">
<p><span class="math inline">\(average\ leverage = \frac{k + 1}{n}\)</span></p>
</div>
<p>In this equation, <em>k</em> stands for the number of predictors (i.e.&nbsp;6) and <em>n</em> for the number of observations (i.e.&nbsp;1188). Therefore, our average leverage can be computed as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>(avg_lvg <span class="ot">&lt;-</span> (<span class="dv">6</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">1188</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.005892256</code></pre>
</div>
</div>
<p>Similar to before, we find different approaches to setting cut-off points for this indicator. While <span class="citation" data-cites="hoaglin1978hat">Hoaglin and Welsch (<a href="references.html#ref-hoaglin1978hat" role="doc-biblioref">1978</a>)</span> argue that a distance twice the average counts as an outlier, <span class="citation" data-cites="stevens2012applied">Stevens (<a href="references.html#ref-stevens2012applied" role="doc-biblioref">2012</a>)</span> (p.&nbsp;105) suggests that values three times higher than the average leverage will negatively affect the model. The rationale is the same as for the externally studentised residuals: If the thresholds are too low, we might find ourselves with many observations, which we would have to investigate further. This might not always be possible or even desirable. However, this should not imply that many outliers are not worth checking. Instead, if there are many, one would have to raise questions about the model itself and whether an important variable needs adding to explain a series of observations that appear to be somewhat ‘off’.</p>
<p>Let’s plot the leverages and use <span class="citation" data-cites="stevens2012applied">Stevens (<a href="references.html#ref-stevens2012applied" role="doc-biblioref">2012</a>)</span> benchmark to draw our reference line.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>m1_outliers <span class="sc">|&gt;</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(rowname, .hat),</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> .hat)) <span class="sc">+</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">3</span> <span class="sc">*</span> avg_lvg, <span class="at">col =</span> <span class="st">"orange"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/avg-lvg-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As before, we want to know which observations fall beyond the threshold.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>new_outliers <span class="ot">&lt;-</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  m1_outliers <span class="sc">|&gt;</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">avglvg =</span> <span class="fu">ifelse</span>(.hat <span class="sc">&gt;</span> <span class="dv">3</span> <span class="sc">*</span> avg_lvg, <span class="st">"TRUE"</span>, <span class="st">"FALSE"</span>)) <span class="sc">|&gt;</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(rowname, avglvg)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Add new results to our reference list</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>outliers <span class="ot">&lt;-</span> <span class="fu">left_join</span>(outliers, new_outliers, <span class="at">by =</span> <span class="st">"rowname"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Looking at our reference object <code>outliers</code>, you will notice that both methods (<code>studresid</code> and <code>avglvg</code>) detect different outliers. Thus, the detection of outliers depends on where we look, i.e.&nbsp;dependent variable or independent variable.</p>
<p>The second method I will cover in this section is the Mahalanobis distance. Luckily the <code>rstatix</code> package includes a handy function <code>mahalanobis_distance()</code> which automatically detects outliers and classifies them for us.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>mhnbs_outliers <span class="ot">&lt;-</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>  m1_outliers <span class="sc">|&gt;</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(new_cases<span class="sc">:</span>travel) <span class="sc">|&gt;</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>  rstatix<span class="sc">::</span><span class="fu">mahalanobis_distance</span>() <span class="sc">|&gt;</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rownames_to_column</span>() <span class="sc">|&gt;</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(rowname, mahal.dist, is.outlier) <span class="sc">|&gt;</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">mhnbs =</span> is.outlier)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Add new results to our reference list</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>outliers <span class="ot">&lt;-</span> <span class="fu">left_join</span>(outliers, mhnbs_outliers, <span class="at">by =</span> <span class="st">"rowname"</span>)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(outliers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,188
Columns: 5
$ rowname    &lt;chr&gt; "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "1…
$ studresid  &lt;chr&gt; "FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALS…
$ avglvg     &lt;chr&gt; "FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALS…
$ mahal.dist &lt;dbl&gt; 5.215, 5.215, 5.215, 5.215, 5.215, 5.215, 5.215, 5.215, 5.2…
$ mhnbs      &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We need to remove mahal.dist because it does not indicate</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># whether a value is an outlier #data-cleaning</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>outliers <span class="ot">&lt;-</span> outliers <span class="sc">|&gt;</span> <span class="fu">select</span>(<span class="sc">-</span>mahal.dist)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>While it is very convenient that this function picks the cut-off point for us, it might be something we would want more control over. As we have learned so far, choosing the ‘right’ cut-off point is essential. Since the values follow a chi-square distribution, we can determine the cut-off points based on the relevant critical value at the chosen p-value. <em>R</em> has a function that allows finding the critical value for our model, i.e.&nbsp;<code>qchisq()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>(mhnbs_th <span class="ot">&lt;-</span> <span class="fu">qchisq</span>(<span class="at">p =</span> <span class="fl">0.05</span>,</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">df =</span> <span class="dv">4</span>,</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">lower.tail =</span> <span class="cn">FALSE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.487729</code></pre>
</div>
</div>
<p>The <code>p</code>-value reflects the probability we are willing to accept that our result is significant/not significant (remember Type I error in <a href="12_power_analysis.html" class="quarto-xref"><span>Chapter 12</span></a>). The value <code>df</code> refers to the degrees of freedom, which relates to the number of independent variables, i.e.&nbsp;<code>4</code>. Thus, it is fairly simple to identify a cut-off point yourself by choosing the <code>p</code>-value you consider most appropriate. The function <code>mahalanobis_distance()</code> assumes <span class="math inline">\(p = 0.01\)</span>, which is certainly a good but strict choice.</p>
<p>If we want to plot outliers as before, we can reuse our code from above and replace it with the relevant new variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>mhnbs_outliers <span class="sc">|&gt;</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(rowname, mahal.dist),</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> mahal.dist)) <span class="sc">+</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> mhnbs_th, <span class="at">col =</span> <span class="st">"orange"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/mahalanobis-distance-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Looking at our <code>outliers</code>, we notice that the Mahalanobis distance identifies more outliers than the leverage, but the same ones.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>outliers <span class="sc">|&gt;</span> <span class="fu">filter</span>(avglvg <span class="sc">==</span> <span class="st">"TRUE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 18 × 4
   rowname studresid avglvg mhnbs
   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;
 1 224     FALSE     TRUE   TRUE 
 2 225     FALSE     TRUE   TRUE 
 3 226     FALSE     TRUE   TRUE 
 4 227     FALSE     TRUE   TRUE 
 5 969     FALSE     TRUE   TRUE 
 6 970     FALSE     TRUE   TRUE 
 7 971     FALSE     TRUE   TRUE 
 8 972     FALSE     TRUE   TRUE 
 9 973     FALSE     TRUE   TRUE 
10 974     FALSE     TRUE   TRUE 
11 975     FALSE     TRUE   TRUE 
12 976     FALSE     TRUE   TRUE 
13 977     FALSE     TRUE   TRUE 
14 978     FALSE     TRUE   TRUE 
15 979     FALSE     TRUE   TRUE 
16 980     FALSE     TRUE   TRUE 
17 981     FALSE     TRUE   TRUE 
18 982     FALSE     TRUE   TRUE </code></pre>
</div>
</div>
<p>Thus, whether you need to use both approaches for the same study is questionable and likely redundant. Still, in a few edge cases, you might want to double-check the results, especially when you feel uncertain which observations should be dealt with later. But, of course, it does not take much time to consider both options.</p>
<p>Besides looking at each side of the regression separately, we might also consider whether removing an observation significantly affects all variables. This is done with outlier detection diagnostics which consider the entire model.</p>
</section>
<section id="sec-outlier-detection-global-measures" class="level4" data-number="13.2.1.3">
<h4 data-number="13.2.1.3" class="anchored" data-anchor-id="sec-outlier-detection-global-measures"><span class="header-section-number">13.2.1.3</span> Outlier detection considering the entire model: Global measures</h4>
<p>To assess the global impact of outliers on the entire regression model, <em>Cook’s d</em> <span class="citation" data-cites="cook1982residuals">(<a href="references.html#ref-cook1982residuals" role="doc-biblioref">Cook and Weisberg 1982</a>)</span> is a popular method in the Social Sciences. It measures to which extend a single observation can affect the predictive power of our model to explain all other observations. Obviously, we do not wish to keep observations that make predicting most of the other observations more challenging. However, as shown in <a href="#tbl-outliers-in-multiple-regressions" class="quarto-xref">Table&nbsp;<span>13.1</span></a>, there are different approaches to this, but some are somewhat redundant. For example, <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> highlight that DDFITS and Cook’s d are ‘interchangeable statistics’ (p.&nbsp;404). Thus, there is no point in demonstrating both since they function similarly. Your decision might be swayed by the preferences of a publisher, editor, lecturer, supervisor or reviewer. Here, I will focus on <em>Cook’s d</em> since it is the approach I see most frequently used in my field. By all means, feel encouraged to go the extra mile and perform the same steps for the DDFITS.</p>
<p>The good news, <code>fortify()</code> automatically added <code>.cooksd</code> to our dataset <code>m1_outliers</code>. Thus, we can immediately compute whether outliers exist and inspect them visually as we did before. A promising starting point to find outliers via the Cook’s D is to plot its distribution.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>m1_outliers <span class="sc">|&gt;</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> rowname,</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> .cooksd)) <span class="sc">+</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/cooks-d-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Inspecting this barplot, we can tell that some observations have much higher <code>.cooksd</code> values than any other observation. Once again, we first need to decide on a benchmark to determine whether we can consider these values as outliers. If we follow <span class="citation" data-cites="cook1982residuals">Cook and Weisberg (<a href="references.html#ref-cook1982residuals" role="doc-biblioref">1982</a>)</span>, values that are higher than 1 (i.e.&nbsp;<span class="math inline">\(d &gt; 1\)</span>) require reviewing. Looking at our plot, none of the observations reaches <code>1</code>, and we need not investigate outliers. Alternatively, <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> suggest that other benchmarks are also worth considering, for example, based on the critical value of an F distribution, which we can determine with the function <code>qf()</code>. This requires us to determine two degrees of freedom (<span class="math inline">\(df_1\)</span> and <span class="math inline">\(df_2\)</span>) and a p-value. To determine these values, <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> suggests <span class="math inline">\(p = 0.5\)</span> and the following formulas to determine the correct <span class="math inline">\(df\)</span>:</p>
<div id="critical-value-cooks-d" data-align="center">
<p><span class="math inline">\(df_1 = k +1\)</span></p>
<p><span class="math inline">\(df_2 = n - k - 1\)</span></p>
</div>
<p>Like the critical value for <a href="#average-leverage-equation" title="average leverage">average leverage</a>, <span class="math inline">\(k\)</span> reflects the number of predictors, and <span class="math inline">\(n\)</span> refers to the sample size. Thus, we can determine the critical value, and therefore our cut-off point as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qf</span>(<span class="at">p =</span> <span class="fl">0.5</span>,</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>   <span class="at">df1 =</span> <span class="dv">4</span> <span class="sc">+</span> <span class="dv">1</span>,</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">df2 =</span> <span class="dv">1188</span> <span class="sc">-</span> <span class="dv">6</span> <span class="sc">-</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8707902</code></pre>
</div>
</div>
<p>This score would also imply that we have no particular outliers to consider, because the highest value in <code>.cooksd</code> is 0.09 computed via <code>max(m1_outliers$.cooksd)</code>.</p>
<p>We might be led to believe that our work is done here, but <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> recommends that any larger deviation is worth inspecting. We do notice that relative to other observations, some cases appear extreme. Ideally, one would further investigate these cases and compare the regression results by removing such extreme cases iteratively. This way, one can assess whether the extreme observations genuinely affect the overall estimates of our model. This would imply repeating steps we already covered earlier when performing multiple regressions with and without outliers. Thus, I will forgo this step here.</p>
<p>In the last chapter about outliers (<a href="#sec-reviewing-the-outliers" class="quarto-xref"><span>Section 13.2.1.5</span></a>), we will rerun the regression without outliers to see how this affects our model estimates. However, before we can do this, we have to cover one more method of detecting outliers.</p>
</section>
<section id="sec-outlier-detection-specific-measures" class="level4" data-number="13.2.1.4">
<h4 data-number="13.2.1.4" class="anchored" data-anchor-id="sec-outlier-detection-specific-measures"><span class="header-section-number">13.2.1.4</span> Outlier detection considering the entire model: Specific measures</h4>
<p>While Cook’s d helps us identify outliers that affect the quality of the entire model, there is also a way to investigate how outliers affect specific predictors. This is achieved with DFBETAS, which, similar to previous methods, assesses the impact of outliers by removing them and measures the impact of such removal on other parts of the regression model.</p>
<p>The function <code>dbetas()</code> takes our model <code>m1</code> and returns the statistics for each predictor in the model. Thus, we do not receive a single score for each observation but multiple for each specific predictor, i.e.&nbsp;each specific measure.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>m1_dfbetas <span class="ot">&lt;-</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dfbetas</span>(m1) <span class="sc">|&gt;</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span>               <span class="co"># convert to tibble for convenience</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rownames_to_column</span>()          <span class="co"># add our rownames</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(m1_dfbetas)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,188
Columns: 6
$ rowname       &lt;chr&gt; "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11",…
$ `(Intercept)` &lt;dbl&gt; 0.02166365, 0.02166365, 0.02166365, 0.02166365, 0.021663…
$ movements     &lt;dbl&gt; -0.0008908373, -0.0008908373, -0.0008908373, -0.00089083…
$ schools       &lt;dbl&gt; -0.01412839, -0.01412839, -0.01412839, -0.01412839, -0.0…
$ businesses    &lt;dbl&gt; -0.002957931, -0.002957931, -0.002957931, -0.002957931, …
$ travel        &lt;dbl&gt; -0.005546516, -0.005546516, -0.005546516, -0.005546516, …</code></pre>
</div>
</div>
<p>All we have to do now is to compare the scores against a benchmark for each variable in this dataset, and we know which observations substantially affect one of the predictors. <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> provides us with the following recommendations for suitable thresholds:</p>
<ul>
<li><p>small or moderate datasets: <span class="math inline">\(DFBETAS &gt; \pm 1\)</span></p></li>
<li><p>large datasets: <span class="math inline">\(DFBETAS &gt; \pm\frac{2}{\sqrt(n)}\)</span></p></li>
</ul>
<p>Since our dataset falls rather into the ‘large’ camp, we should choose the second option. Again, <span class="math inline">\(n\)</span> stands for the sample size. Let’s create an object to store this value.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>(dfbetas_th <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">1188</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.05802589</code></pre>
</div>
</div>
<p>For demonstration purposes, I will pick <code>movements</code> to check for outliers. If this was a proper analysis for a project, you would have to compare this indicator against each variable separately. As the benchmarks indicate, the DFBETAS value can be positive or negative. So, when we compare the calculated values with it, we can look at the absolute value, i.e.&nbsp;use <code>abs()</code>, which turns all values positive. This makes it much easier to compare observations against a threshold and we could do this for any assessment of outliers against a benchmark.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check whether values exceed the threshold</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>dfbetas_check <span class="ot">&lt;-</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>  m1_dfbetas <span class="sc">|&gt;</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dfbetas_movements =</span> <span class="fu">ifelse</span>(<span class="fu">abs</span>(movements) <span class="sc">&gt;</span> dfbetas_th,</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"TRUE"</span>,</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"FALSE"</span>)) <span class="sc">|&gt;</span></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(rowname, dfbetas_movements)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Add result to our outliers object</span></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>outliers <span class="ot">&lt;-</span></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>  outliers <span class="sc">|&gt;</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(dfbetas_check, <span class="at">by =</span> <span class="st">"rowname"</span>)</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(outliers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,188
Columns: 5
$ rowname           &lt;chr&gt; "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "…
$ studresid         &lt;chr&gt; "FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALSE"…
$ avglvg            &lt;chr&gt; "FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALSE"…
$ mhnbs             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ dfbetas_movements &lt;chr&gt; "FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALSE"…</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># some housekeeping, i.e. making all columns &lt;lgl&gt; except for rowname</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>outliers <span class="ot">&lt;-</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>  outliers <span class="sc">|&gt;</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rowname =</span> <span class="fu">as_factor</span>(rowname)) <span class="sc">|&gt;</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_if</span>(is.character, as.logical)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(outliers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,188
Columns: 5
$ rowname           &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…
$ studresid         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ avglvg            &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ mhnbs             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ dfbetas_movements &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…</code></pre>
</div>
</div>
<p>Of course, we can also visualise the outliers as we did before.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>m1_dfbetas <span class="sc">|&gt;</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> rowname,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> movements)) <span class="sc">+</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> dfbetas_th, <span class="at">col =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="sc">-</span>dfbetas_th, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/dfbetas-plot-outliers-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>I want to take this opportunity to show that sometimes we can make visualisations even simpler. Remember, we used <code>abs()</code> to make all values positive? We can apply the same principle here. This way, we only need one line to indicate the threshold. In addition, we could also plot multiple variables at once. Instead of defining the <code>aes()</code> inside the <code>ggplot()</code> function, we can define it independently for each <code>geom_point()</code>. What do you think about the following version of the same plot?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>m1_dfbetas <span class="sc">|&gt;</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(rowname, <span class="fu">abs</span>(movements)),</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">y =</span> <span class="fu">abs</span>(movements),</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">col =</span> <span class="st">"movements"</span>),</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="fl">0.5</span>,</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> rowname,</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>                 <span class="at">y =</span> <span class="fu">abs</span>(travel),</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>                 <span class="at">col =</span> <span class="st">"travel"</span>),</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="fl">0.5</span>,</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> dfbetas_th, <span class="at">col =</span> <span class="st">"#FF503A"</span>) <span class="sc">+</span></span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"movements"</span> <span class="ot">=</span> <span class="st">"#2EA5FF"</span>,</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"travel"</span> <span class="ot">=</span> <span class="st">"#7DB33B"</span>)) <span class="sc">+</span></span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Label the legend appropriately</span></span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">col =</span> <span class="st">"COVID measures"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/dfbetas-plot-outliers-alternative-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>After <code>reorder()</code>ing the variable <code>movements</code> and plotting <code>travel</code> as well, we notice that there might be slightly fewer outliers for <code>movements</code> than for <code>travel</code>. Thus, some observations affect some predictors more strongly than others.</p>
</section>
<section id="sec-reviewing-the-outliers" class="level4" data-number="13.2.1.5">
<h4 data-number="13.2.1.5" class="anchored" data-anchor-id="sec-reviewing-the-outliers"><span class="header-section-number">13.2.1.5</span> Reviewing the outliers</h4>
<p>After all this hard work and what turned out to be a very lengthy chapter, we finally arrive at the point where we check which observations we might wish to remove or handle in some shape or form. First, we want to know which observations are affected. Therefore we need to review our reference data in the object <code>outliers</code>. We want to see all observations identified by one or more diagnostic tools as an outlier. There are two ways to achieve this. First, we can use what we have learned so far and <code>filter()</code> each column for the value TRUE. This is the hard way of doing it, and if you have many more columns, this will take a little while and potentially drive you insane. The easy (and clever) way of filtering across multiple columns can be achieved by turning multiple columns into a single column. In the <code>tidyverse</code>, this is called <code>pivot_longer()</code> and we performed it earlier in <a href="11_group_comparison.html#sec-sphericity" class="quarto-xref"><span>Section 11.3.2.1</span></a>. Thus, it might seem less complicated than expected. Let’s do this step-by-step as we did for <code>pivot_wider()</code> in <a href="11_group_comparison.html#sec-chi-squared-test" class="quarto-xref"><span>Section 11.4</span></a>. Currently, our data has five columns, of which four are different measures to detect outliers. Our goal is to create a table that has only three columns:</p>
<ul>
<li><p><code>rowname</code>, which we keep unchanged because it is the ID that identifies each observation in our data</p></li>
<li><p><code>outlier_measure</code>, which is the variable that indicates which measure was used to find an outlier.</p></li>
<li><p><code>is.outlier</code>, which contains the values from the tibble, i.e.&nbsp;the cell values of <code>TRUE</code> and <code>FALSE</code>.</p></li>
</ul>
<p>Here is an example of what we want to achieve. Imagine we have a smaller dataset, which contains three columns, two of which are outlier detection measures, i.e.&nbsp;<code>studresid</code> and <code>mhbns</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">tribble</span>(</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span>rowname,   <span class="sc">~</span> studresid,    <span class="sc">~</span>mhbns,</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>         <span class="st">"1"</span>,       <span class="cn">FALSE</span>,     <span class="cn">FALSE</span>,</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>         <span class="st">"2"</span>,        <span class="cn">TRUE</span>,     <span class="cn">FALSE</span>,</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>         <span class="st">"3"</span>,        <span class="cn">TRUE</span>,      <span class="cn">TRUE</span></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  rowname studresid mhbns
  &lt;chr&gt;   &lt;lgl&gt;     &lt;lgl&gt;
1 1       FALSE     FALSE
2 2       TRUE      FALSE
3 3       TRUE      TRUE </code></pre>
</div>
</div>
<p>To filter for outliers using a single column/variable, we need to rearrange the values in <code>studresid</code> and <code>mhbns</code>. We currently have one column which captures the <code>rowname</code>, and two other columns which are both outlier detection methods. Thus, we could argue that <code>studresid</code> and <code>mhbns</code> measure the same, but with different methods. Therefore we can combine them into a factor, e.g.&nbsp;<code>is.outlier</code>, with two levels reflecting each outlier detection method. At the moment, we have two values recorded for every row in this dataset. For example, the first observation has the values <code>studresid == FALSE</code> and <code>mhnbs == FALSE</code>. If we want to combine these two observations into a single column, we need to have two rows with the <code>rowname</code> <code>1</code> to ensure that each row still only contains one observation, i.e.&nbsp;a tidy dataset. Therefore, we end up with more rows than our original dataset, hence, a ‘longer’ dataset. Here is how we can do this automatically:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>data_long <span class="ot">&lt;-</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">|&gt;</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="sc">!</span>rowname,</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"outlier_measure"</span>,</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"is.outlier"</span>)</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>data_long</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 3
  rowname outlier_measure is.outlier
  &lt;chr&gt;   &lt;chr&gt;           &lt;lgl&gt;     
1 1       studresid       FALSE     
2 1       mhbns           FALSE     
3 2       studresid       TRUE      
4 2       mhbns           FALSE     
5 3       studresid       TRUE      
6 3       mhbns           TRUE      </code></pre>
</div>
</div>
<p>Instead of three rows, we have six, and all the outlier detection values (i.e.&nbsp;all <code>TRUE</code> and <code>FALSE</code> values) are now in one column, i.e.&nbsp;<code>is.outlier</code>. However, what exactly did just happen in this line of code? In light of what we specified above, we did three things inside the function <code>pivot_longer()</code>:</p>
<ul>
<li><p>We excluded <code>rownames</code> from being pivoted, i.e.&nbsp;<code>cols = !rowname</code>.</p></li>
<li><p>We specified a column where all the column names go to, i.e.&nbsp;<code>names_to = "outlier_measure"</code>.</p></li>
<li><p>We defined a column where all cell values should be listed, i.e.&nbsp;<code>values_to = "is.outlier"</code>.</p></li>
</ul>
<p>From here, it is straightforward to <code>count()</code> the number of <code>is.outlier</code> per <code>rowname</code> and <code>filter()</code> out those that return a value of <code>TRUE</code>. Everything we learned is now easily applicable without overly complicated functions or many repetitions. As mentioned earlier, pivoting datasets is an essential data wrangling skill, not matter which software you prefer.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>data_long <span class="sc">|&gt;</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(rowname, is.outlier) <span class="sc">|&gt;</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(is.outlier <span class="sc">==</span> <span class="st">"TRUE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  rowname is.outlier     n
  &lt;chr&gt;   &lt;lgl&gt;      &lt;int&gt;
1 2       TRUE           1
2 3       TRUE           2</code></pre>
</div>
</div>
<p>Et voilà. We now counted the number of times an observation was detected considering both measures. This is scalable to more than two measures. Thus, we can apply it to our data as well.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>outliers_true <span class="ot">&lt;-</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>  outliers <span class="sc">|&gt;</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">!</span>rowname,</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"measure"</span>,</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"is.outlier"</span>) <span class="sc">|&gt;</span></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(rowname, is.outlier) <span class="sc">|&gt;</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(is.outlier <span class="sc">==</span> <span class="st">"TRUE"</span>)</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>outliers_true</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 85 × 3
   rowname is.outlier     n
   &lt;fct&gt;   &lt;lgl&gt;      &lt;int&gt;
 1 224     TRUE           2
 2 225     TRUE           2
 3 226     TRUE           2
 4 227     TRUE           2
 5 344     TRUE           1
 6 345     TRUE           1
 7 346     TRUE           1
 8 349     TRUE           1
 9 350     TRUE           1
10 351     TRUE           1
# ℹ 75 more rows</code></pre>
</div>
</div>
<p>The result is a <code>tibble</code> which tells us that we identified 85 distinct outliers. This might sound like a lot, but we also have to remember that our dataset consists of 1188 observations, i.e.&nbsp;7% of our data are outliers.</p>
<p>Since the output is relatively long, we might want to plot the outcome to get an idea of the bigger picture.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>outliers_true <span class="sc">|&gt;</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(rowname, n),</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> n)) <span class="sc">+</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/number-of-outliers-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>A few observations were detected by three out of the four methods we used to detect outliers. There are some more which were detected by two different methods. However, there are also more than half of our outliers which were only detected by one method.</p>
<p>As highlighted in <a href="09_sources_of_bias.html#sec-dealing-with-outliers" class="quarto-xref"><span>Section 9.6</span></a>, there are many ways we can go about outliers. To keep our analysis simple, I intend to remove those observations detected by multiple methods rather than only by one. Whether this approach is genuinely appropriate is a matter of further investigation. I take a very pragmatic approach with our sample data. However, it is worth reviewing the options available to transform data, as covered by <span class="citation" data-cites="field2013discovering">Field (<a href="references.html#ref-field2013discovering" role="doc-biblioref">2013</a>)</span> (p.203). Data transformation can help to deal with outliers instead of removing or imputing them. Still, data transformation comes with severe drawbacks and in most cases, using a bootstrapping technique to account for violations of parametric conditions is often more advisable. Bootstrapping refers to the process of randomly resampling data from your dataset and rerun the same test multiple times, e.g.&nbsp;2000 times. Thus, there will be some samples that do not include the outliers. The process is somewhat similar to multiple imputation (see <a href="07_data_wrangling.html#sec-replacing-removing-missing-data" class="quarto-xref"><span>Section 7.7.3</span></a>). Still, instead of estimating a specific value in our dataset, we estimate statistical parameters, e.g.&nbsp;confidence intervals or regression coefficients (i.e.&nbsp;estimates). The package <code>rsample</code> allows implementing bootstrapping straightforwardly. However, bootstrapping comes at the cost of lower power because we are running the test so many times.</p>
<p>For now, I settle on removing outliers entirely. The easiest way to remove these outliers is to combine our <code>outliers</code> dataset with our regression (<code>m1_outliers</code>). Now you will notice that having <code>rowname</code> as an ID allows us to match the values of each table to each other. Otherwise, this would not be possible.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Include outliers which were detected by multiple methods</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>outliers_select <span class="ot">&lt;-</span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>  outliers_true <span class="sc">|&gt;</span></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(n <span class="sc">&gt;</span> <span class="dv">1</span>)</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only columns which are NOT included in outliers_select</span></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>m1_no_outliers <span class="ot">&lt;-</span> <span class="fu">anti_join</span>(m1_outliers, outliers_select, <span class="at">by =</span> <span class="st">"rowname"</span>)</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>m1_no_outliers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1,152 × 13
   rowname new_cases movements schools businesses travel    .hat .sigma  .cooksd
   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
 1 1               0         0       0          0      0 0.00516 10077.  9.39e-5
 2 2               0         0       0          0      0 0.00516 10077.  9.39e-5
 3 3               0         0       0          0      0 0.00516 10077.  9.39e-5
 4 4               0         0       0          0      0 0.00516 10077.  9.39e-5
 5 5               0         0       0          0      0 0.00516 10077.  9.39e-5
 6 6               0         0       0          0      0 0.00516 10077.  9.39e-5
 7 7               0         0       0          0      0 0.00516 10077.  9.39e-5
 8 8               0         0       0          0      0 0.00516 10077.  9.39e-5
 9 9               0         0       0          0      0 0.00516 10077.  9.39e-5
10 10              0         0       0          0      0 0.00516 10077.  9.39e-5
# ℹ 1,142 more rows
# ℹ 4 more variables: .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;, .stdresid &lt;dbl&gt;,
#   .studresid &lt;dbl&gt;</code></pre>
</div>
</div>
<p>The function <code>anti_join()</code> does exactly what the name implies. It takes the first data frame (i.e.&nbsp;<code>m1_outliers</code>) and removes values that are included in the second data frame (i.e.&nbsp;<code>outliers_select()</code>). This is tremendously helpful when performing such complex outlier detection and removing them all in one go.</p>
<p>As the final step, we want to compare how the removal of outliers affected our model. Ideally, we managed to improve the regression. Thus, we compare our old model <code>m1</code> with a new model <code>m2</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Original regression</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(new_cases <span class="sc">~</span> movements <span class="sc">+</span> schools <span class="sc">+</span> businesses <span class="sc">+</span> travel,</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> covid_uk_ger)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression with outliers removed</span></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(new_cases <span class="sc">~</span> movements <span class="sc">+</span> schools <span class="sc">+</span> businesses <span class="sc">+</span> travel,</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> m1_no_outliers)</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the parameters between models</span></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a><span class="co"># I added some reformatting, because</span></span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a><span class="co"># I prefer a regular tibble over a pre-formatted</span></span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a><span class="co"># table. Technically you only need the first line.</span></span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">compare_parameters</span>(m1, m2) <span class="sc">|&gt;</span></span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Parameter, Coefficient.m1, p.m1, Coefficient.m2, p.m2) <span class="sc">|&gt;</span></span>
<span id="cb81-16"><a href="#cb81-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.double), round, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 5
  Parameter   Coefficient.m1  p.m1 Coefficient.m2  p.m2
  &lt;chr&gt;                &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;
1 (Intercept)        -3024.      0       -1543.   0.031
2 movements            -64.0     0         -15.8  0.174
3 schools              382.      0         320.   0    
4 businesses            90.5     0          82.7  0    
5 travel                45.7     0          -1.27 0.875</code></pre>
</div>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the performance between models</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">compare_performance</span>(m1, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Comparison of Model Performance Indices

Name | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) |    R2 | R2 (adj.) |      RMSE |     Sigma
--------------------------------------------------------------------------------------------------------------
m1   |    lm | 25279.5 (&lt;.001) | 25279.6 (&lt;.001) | 25310.0 (&lt;.001) | 0.229 |     0.227 | 10052.123 | 10073.343
m2   |    lm | 24099.6 (&gt;.999) | 24099.7 (&gt;.999) | 24129.9 (&gt;.999) | 0.179 |     0.177 |  8398.110 |  8416.395</code></pre>
</div>
</div>
<p>If you look at <code>R2 (adj.)</code> you might feel a sense of disappointment. How does the model explain less variance? If we consider <code>AIC</code>, <code>BIC</code> and <code>RMSE</code>, we improved the model because their values are lower for <code>m2</code>. However, it seems that the outliers affected <code>R2</code>, which means they inflated this model indicator. In other words, our regression explains less than we hoped for. However, we can be more confident that the predictions of this model will be more accurate.</p>
<p>If we inspect the estimates more closely, we also notice that <code>movements</code> (where we removed outliers) and <code>travel</code> are not significant anymore (i.e.&nbsp;<code>p.m2 &gt; 0.05</code>). We should remove these from our model since they do not help explain the variance of <code>new_cases</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(new_cases <span class="sc">~</span> schools <span class="sc">+</span> businesses,</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> m1_no_outliers)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">model_parameters</span>(m3) <span class="sc">|&gt;</span></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Parameter, Coefficient, p) <span class="sc">|&gt;</span></span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.double), round, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  Parameter   Coefficient     p
  &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;
1 (Intercept)     -1664.  0.016
2 schools           307.  0    
3 businesses         78.9 0    </code></pre>
</div>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">model_performance</span>(m3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Indices of model performance

AIC       |      AICc |       BIC |    R2 | R2 (adj.) |     RMSE |    Sigma
---------------------------------------------------------------------------
24098.209 | 24098.243 | 24118.406 | 0.178 |     0.176 | 8407.515 | 8418.483</code></pre>
</div>
</div>
<p>Similar to before, after removing the insignificant predictors, we end up with an equally good model (in terms of <span class="math inline">\(adjusted\ R^2\)</span>, but we need fewer variables to explain the same amount of variance in <code>new_cases</code>. Our final model <code>m3</code> is a parsimonious and less complex model.</p>
</section>
</section>
<section id="sec-standardised-beta-vs-unstandardised-beta" class="level3" data-number="13.2.2">
<h3 data-number="13.2.2" class="anchored" data-anchor-id="sec-standardised-beta-vs-unstandardised-beta"><span class="header-section-number">13.2.2</span> Standardised beta (<span class="math inline">\(\beta\)</span>) vs.&nbsp;unstandardised beta (<span class="math inline">\(B\)</span>)</h3>
<p>In multiple regressions, we often use variables that are measured in different ways and which use different measurement units, e.g.&nbsp;currency, age, etc. Thus, it is sometimes fairly difficult to interpret regression coefficients without standardising the measurement units. Standardised scores (also called <em>z-scores</em>) imply that each variable has a distribution where the mean equals <code>0</code> and the standard deviation equals <code>1</code>. By transforming our variables to z-scores, they become ‘unit free’ <span class="citation" data-cites="cohen2014applied">(<a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>)</span> (p.&nbsp;25) and are easier to interpret. Here is an example with a simplified dataset:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create some data</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>))</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute z-scores</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">|&gt;</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">x_scaled =</span> <span class="fu">scale</span>(x))</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the mean and sd for each variable</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a><span class="co"># and put it into a nice table</span></span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">variable =</span> <span class="fu">c</span>(<span class="st">"x"</span>, <span class="st">"x_scaled"</span>),</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean =</span> <span class="fu">c</span>(<span class="fu">mean</span>(data<span class="sc">$</span>x), <span class="fu">mean</span>(data<span class="sc">$</span>x_scaled)),</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> <span class="fu">c</span>(<span class="fu">sd</span>(data<span class="sc">$</span>x), <span class="fu">sd</span>(data<span class="sc">$</span>x_scaled))</span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  variable  mean    sd
  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;
1 x          2.5  1.29
2 x_scaled   0    1   </code></pre>
</div>
</div>
<p>If you feel that my choice of values has likely affected the outcome, please feel free to change the values for x in this code chunk to whatever you like. The results for <code>x_scaled</code> will always remain the same. There is something else that remains the same: the actual distribution. Because we are only rescaling our data, we are not affecting the differences between these scores. We can show this in a scatterplot and by running a correlation. Both will show that these variables are perfectly correlated. Therefore, our transformations did not affect the relative relationship of values to each other.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>data <span class="sc">|&gt;</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x,</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> x_scaled)) <span class="sc">+</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> x,</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/scaled-unscaled-data-comparison-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>correlation<span class="sc">::</span><span class="fu">correlation</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Correlation Matrix (pearson-method)

Parameter1 | Parameter2 |    r |       95% CI | t(2) |         p
----------------------------------------------------------------
x          |   x_scaled | 1.00 | [1.00, 1.00] |  Inf | &lt; .001***

p-value adjustment method: Holm (1979)
Observations: 4</code></pre>
</div>
</div>
<p>It is not a bad idea for regressions to report both unstandardised (<span class="math inline">\(B\)</span>) and standardised (<span class="math inline">\(\beta\)</span>) values for each predictor, because comparing predictors based on standardised <span class="math inline">\(\beta\)</span>s only could lead to misleading interpretations as the differences in coefficients could not relate to the true effect size but differences in standard deviations. Let’s look at an example where this issues becomes more evident. Consider the <code>swm</code> dataset which contains the variables <code>salary</code>, <code>work_experience</code> and <code>mindfulness</code>. We are curious to know to which extend <code>work_experience</code> and <code>mindfulness</code> predict <code>salary</code>. In a first step, we run the model with scaled variables which returns standardised <span class="math inline">\(\beta\)</span> coefficients.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple regression model with scaled variables</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">scale</span>(salary) <span class="sc">~</span> <span class="fu">scale</span>(work_experience) <span class="sc">+</span> <span class="fu">scale</span>(mindfulness),</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> swm)</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = scale(salary) ~ scale(work_experience) + scale(mindfulness), 
    data = swm)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.72465 -0.36714  0.05038  0.41489  2.05082 

Coefficients:
                         Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)            -3.128e-16  6.244e-02   0.000        1    
scale(work_experience)  6.451e-01  6.337e-02  10.179  &lt; 2e-16 ***
scale(mindfulness)      5.475e-01  6.337e-02   8.639 1.16e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.6244 on 97 degrees of freedom
Multiple R-squared:  0.6179,    Adjusted R-squared:  0.6101 
F-statistic: 78.45 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Considering the outcome, it would seem that both variables are good predictors for <code>salary</code> and their <code>Estimate</code>s are almost the same. Thus, one could be fooled into thinking that they are equally important. We can repeat the analysis but obtain unstandardised <span class="math inline">\(\beta\)</span>s.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple regression model with scaled variables</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> work_experience <span class="sc">+</span> mindfulness,</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> swm)</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = salary ~ work_experience + mindfulness, data = swm)

Residuals:
    Min      1Q  Median      3Q     Max 
-29.739  -6.331   0.869   7.154  35.363 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     -20.15294   12.56370  -1.604    0.112    
work_experience   2.42379    0.23811  10.179  &lt; 2e-16 ***
mindfulness       0.49650    0.05747   8.639 1.16e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 10.77 on 97 degrees of freedom
Multiple R-squared:  0.6179,    Adjusted R-squared:  0.6101 
F-statistic: 78.45 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>This time the <code>Estimate</code>s are quite different from each other, i.e.&nbsp;<span class="math inline">\(work\_experience = 2.42\)</span> and <span class="math inline">\(mindfulness = 0.50\)</span>. Considering these results it becomes clear that <code>work_experience</code> has a much stronger impact on <code>salary</code> than <code>mindfulness</code>. We can further confirm this by graphing the regression lines for each variable separately.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>swm <span class="sc">|&gt;</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(work_experience, mindfulness),</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"value"</span>,</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"variable"</span>) <span class="sc">|&gt;</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> value,</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> salary,</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">col =</span> variable,</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">group =</span> variable)) <span class="sc">+</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> x,</span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">FALSE</span>,</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>              <span class="at">col =</span> <span class="st">"#3e3c42"</span>) <span class="sc">+</span></span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Choose custom colours for the dots</span></span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"#5c589a"</span>, <span class="st">"#fc5c5d"</span>)) <span class="sc">+</span></span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a>  ggdist<span class="sc">::</span><span class="fu">theme_ggdist</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="13_regressions_files/figure-html/visualising-swm-regression-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We can see that while <code>work_experience</code> is more centralised around its regression line, <code>mindfulness</code> is much more spread out across the x-axis. In other words, the standard deviation of <code>mindfulness</code> is much larger.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing the standard deviation</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>swm <span class="sc">|&gt;</span></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">work_xp_sd =</span> <span class="fu">sd</span>(work_experience),</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">mindfulness_sd =</span> <span class="fu">sd</span>(mindfulness)</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>            )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
  work_xp_sd mindfulness_sd
       &lt;dbl&gt;          &lt;dbl&gt;
1       4.59           19.0</code></pre>
</div>
</div>
<p>We can also see that the slope of the regression line is different, indicating that a small change in <code>work_experience</code> has a much greater impact on <code>salary</code> than <code>minfulness</code>. Thus, we need to be very careful when interpreting standardised coefficients. Of course, when in doubt (or simply confused), a data visualisation like this one can provide more certainty about the relationship of variables and their strength.</p>
<p>Unfortunately, this is not the end of the story because ‘standardisation’ can mean different things. We can generate standardised <span class="math inline">\(\beta\)</span> after the fact (post-hoc) or decide to ‘refit’ our regression with standardised predictors, i.e.&nbsp;before we run the regression. Both options are appropriate, but the scores will differ slightly. However, the main idea remains the same: We want to interpret different regression coefficients based on their standard deviations and not their absolute scores. In R, many different packages offer standardised estimates. One package I particularly recommend is <code>parameters</code>. It provides various options for returning our estimates from a linear model by specifying the <code>standardize</code> argument (see <a href="https://easystats.github.io/parameters/reference/model_parameters.default.html" target="blank" title="detailed documentation">detailed documentation</a>). Of course, you can also opt to scale the variables by hand, using the <code>scale()</code> function, as we did in the previous examples. All three approaches are shown in the following code chunk.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scaling 'by hand'</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>m3_scaled <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">scale</span>(new_cases) <span class="sc">~</span></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">scale</span>(schools) <span class="sc">+</span></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">scale</span>(businesses),</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> m1_no_outliers)</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">model_parameters</span>(m3_scaled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parameter   | Coefficient |   SE |        95% CI |  t(1149) |      p
--------------------------------------------------------------------
(Intercept) |    2.00e-15 | 0.03 | [-0.05, 0.05] | 7.49e-14 | &gt; .999
schools     |        0.29 | 0.03 | [ 0.23, 0.34] |     9.90 | &lt; .001
businesses  |        0.21 | 0.03 | [ 0.16, 0.27] |     7.38 | &lt; .001</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed
  using a Wald t-distribution approximation.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scaling using 'parameters' package with refit</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This is equivalent to scaling 'by hand'</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">model_parameters</span>(m3, <span class="at">standardize =</span> <span class="st">"refit"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parameter   | Coefficient |   SE |        95% CI |   t(1149) |      p
---------------------------------------------------------------------
(Intercept) |   -4.99e-15 | 0.03 | [-0.05, 0.05] | -1.87e-13 | &gt; .999
schools     |        0.29 | 0.03 | [ 0.23, 0.34] |      9.90 | &lt; .001
businesses  |        0.21 | 0.03 | [ 0.16, 0.27] |      7.38 | &lt; .001</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed
  using a Wald t-distribution approximation.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scaling using `parameters` package without refitting the model</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">model_parameters</span>(m3, <span class="at">standardize =</span> <span class="st">"posthoc"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parameter   | Std. Coef. |   SE |         95% CI | t(1149) |      p
-------------------------------------------------------------------
(Intercept) |       0.00 | 0.00 | [ 0.00,  0.00] |   -2.41 | 0.016 
schools     |       0.29 | 0.03 | [ 0.23,  0.34] |    9.90 | &lt; .001
businesses  |       0.21 | 0.03 | [ 0.16,  0.27] |    7.38 | &lt; .001</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed
  using a Wald t-distribution approximation.</code></pre>
</div>
</div>
<p>I prefer to standardise using the <code>parameters</code> package because it makes my life easier, and I need to write less code. I can also easily compare results before scaling my variables. The choice is yours, of course. Also, I tend to use <code>standardize = refit</code> in most regressions, since it is more in line with what most Social Scientists seem to report in their publications.</p>
</section>
<section id="sec-multicollinearity" class="level3" data-number="13.2.3">
<h3 data-number="13.2.3" class="anchored" data-anchor-id="sec-multicollinearity"><span class="header-section-number">13.2.3</span> Multicollinearity: The dilemma of highly correlated independent variables</h3>
<p>We finished fitting our model, and we are likely exhausted but also happy that we accomplished something. However, we are not yet done with our analysis. One of the essential post-tests for multiple regressions is a test for <em>multicollinearity</em> or sometimes referred to as <em>collinearity</em>. The phenomenon of multicollinearity defines a situation in which some of our independent variables can be explained by other independent variables in our regression model. In other words, there exists a substantial correlation (a linear relationship) between two or more independent variables. However, it is crucial to not confuse this with correlations between a dependent variable and independent variables. Remember, a regression reflects the linear relationship between the predictor variables and the outcome variable. As such, we do hope to find a correlation between these variables, just not among the independent variables.</p>
<p>If we have evidence that multicollinearity exists in our data, we face some problems <span class="citation" data-cites="cohen2014applied field2013discovering sage-methods2004dbw">(<a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>; <a href="references.html#ref-field2013discovering" role="doc-biblioref">Field 2013</a>; <a href="references.html#ref-sage-methods2004dbw" role="doc-biblioref">Grandstrand 2004</a>)</span>:</p>
<ul>
<li><p><em>Unstable regression Coefficients</em>: We cannot trust our regression coefficients, i.e.&nbsp;our estimates (<span class="math inline">\(\beta\)</span>), because the standard errors could be inflated and therefore affect statistical significance.</p></li>
<li><p><em>Ambiguity in variable importance</em>: Since two independent variables can explain the same variance, it is unclear which one is important since both can be easily interchanged without affecting the model much.</p></li>
<li><p><em>Challenges in hypothesis testing</em>: Due to inflated standard errors and unstable estimates, it can be challenging to conduct reliable hypothesis tests, leading to potential confusion about the importance of predictors.</p></li>
<li><p><em>Underestimation of model variance</em>: We likely underestimate the variance our model can explain, i.e.&nbsp;our <span class="math inline">\(R^2\)</span>.</p></li>
<li><p><em>Increased Type II errors</em>: We produce more Type II errors, i.e.&nbsp;we likely reject significant predictors due to statistical insignificance because of the potentially inflated standard errors.</p></li>
</ul>
<p>The <em>Variance Inflation Factor (VIF)</em> and its little sibling <em>Tolerance</em> are methods to identify issues of multicollinearity. Compared to detecting outliers, it is very simple to compute these indicators and surprisingly uncomplicated to interpret them. The package <code>performance</code> offers a simple function called <code>check_collinearity()</code> which provides both. The tolerance can be calculated from the VIF as <span class="math inline">\(tolerance = \frac{1}{VIF}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">check_collinearity</span>(m3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Check for Multicollinearity

Low Correlation

       Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI
    schools 1.18 [1.12, 1.28]         1.09      0.85     [0.78, 0.89]
 businesses 1.18 [1.12, 1.28]         1.09      0.85     [0.78, 0.89]</code></pre>
</div>
</div>
<p>As the output already indicates, there is a <code>Low Correlation</code> between our independent variables. So, good news for us. In terms of interpretations, we find the following benchmarks as recommendations to determine multicollinearity <span class="citation" data-cites="field2013discovering">(<a href="references.html#ref-field2013discovering" role="doc-biblioref">Field 2013</a>)</span> :</p>
<ul>
<li><p><code>VIF &gt; 10</code>: Evidence for multicollinearity</p></li>
<li><p><code>mean(VIF) &gt; 1</code>: If the mean of all VIFs lies substantially above <code>1</code>, multicollinearity might be an issue.</p></li>
<li><p><code>Tolerance &lt; 0.1</code>: Multicollinearity is a severe concern. This is the same condition as <code>VIF &gt; 10</code>.</p></li>
<li><p><code>Tolerance &lt; 0.2</code>: Multicollinearity could be a concern. This is the same condition as <code>VIF &gt; 5</code>.</p></li>
</ul>
<p>However, <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> warns to not rely on these indicators alone. There is sufficient evidence that lower VIF scores could also cause issues. Thus, it is always important to still investigate relationships of independent variables statistically (e.g.&nbsp;correlation) and visually (e.g.&nbsp;scatterplots). For example, outliers can often be a cause for too high or too low VIFs. In short, the simplicity in the computation of these indicators should not be mistaken as a convenient shortcut.</p>
<p>Sometimes, the errors (or residuals) in a regression model can be closely related to each other as well, which is called <em>autocorrelation</em>. Imagine if the mistakes you make when predicting someone’s salary were similar every time - maybe you always underestimate how much someone earns after they reach a certain level or work experience. This pattern can be a problem because regression analysis assumes that these errors should be random and independent from one another. When they are not, it can make our results unreliable, meaning we cannot trust whether our findings are accurate. The <em>Durbin-Watson Test</em> offers an equally easy way to detect autocorrelation among residuals. We can use the <code>car</code> package and the function <code>durbinWatsonTest()</code> to retrieve the relevant information.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">durbinWatsonTest</span>(m3) <span class="sc">|&gt;</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>  broom<span class="sc">::</span><span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 5
  statistic p.value autocorrelation method             alternative
      &lt;dbl&gt;   &lt;dbl&gt;           &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt;      
1     0.135       0           0.930 Durbin-Watson Test two.sided  </code></pre>
</div>
</div>
<p>The <code>statistic</code> of the Durbin-Watson Test can range from 0 to 4, where 2 indicates no correlation. Luckily for us, we do not have to guess whether the difference from our computation is significantly different from 2 because we also get the <code>p.value</code> for such test. In our case, our model suffers from strong correlation of error terms because <span class="math inline">\(p.value &lt; 0.05\)</span>.</p>
<p>If we wanted to remedy autocorrelation (and to some extend multicollinearity as well), we could consider, for example:</p>
<ul>
<li><p>Revisiting the regression model and potentially dropping those variables that measure the same or similar underlying factors <span class="citation" data-cites="cohen2014applied">(<a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>)</span>.</p></li>
<li><p>We could collect more data because a larger dataset will always increase the precision of the regression coefficients <span class="citation" data-cites="cohen2014applied">(<a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>)</span>.</p></li>
<li><p>Use different modelling techniques <span class="citation" data-cites="cohen2014applied">(<a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>)</span> which can resolve such issues, for example, using generalised least squares (GLS) models and transform some variables of concern <span class="citation" data-cites="sage-methods2004dbw">(<a href="references.html#ref-sage-methods2004dbw" role="doc-biblioref">Grandstrand 2004</a>)</span>.</p></li>
</ul>
<p>The cause for autocorrelation is often rooted in either <em>‘clustered data’</em> or a <em>‘serial dependency’</em> <span class="citation" data-cites="cohen2014applied">(<a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>)</span>. In our dataset, both could apply. First, we have data that was collected over time, which could lead to wrong standard errors if not accounted for. Second, we have data from two different countries (<code>United Kingdom</code> and <code>Germany</code>). Thus, our data might be clustered.</p>
<p>To remove serial dependency effects, we would have to transform data and account for the correlation across time. Such a technique is shown in <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> (p.149). Furthermore, to counteract the issue of clustered data, we need to use multilevel regression models, also known as hierarchical regressions, which we will cover in the next chapter.</p>
</section>
</section>
<section id="sec-hierarchical-regression" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="sec-hierarchical-regression"><span class="header-section-number">13.3</span> Hierarchical regression</h2>
<p>Adding independent variables to a regression model often happens in a stepwise approach, i.e.&nbsp;we do not add all independent variables at once. Instead, we might first add the essential variables (based on prior research), run the regression, and then examine the results. After that, we add more variables that could explain our dependent variable and rerun the regression. This results in two models which we can compare and identify improvements.</p>
<p>In hierarchical regressions, we most frequently distinguish three types of independent variables, which also reflect the order in which we add variables to a multiple regression:</p>
<ol type="1">
<li><p><em>Control variables</em>: These are independent variables that might affect the dependent variable somehow, and we want to make sure its effects are accounted for. Control variables tend to be not the primary focus of a study but ensure that other independent variables (the main effects) are not spurious. Control variables are added first to a regression.</p></li>
<li><p><em>Main effects variables</em>: These are the independent variables that the researcher expects will predict the dependent variable best. Main effects variables are added after any control variables.</p></li>
<li><p><em>Moderating variables</em>: These are variables that attenuate the strength of the relationship between independent and dependent variables. They are also referred to as <em>interactions</em> or <em>interaction terms.</em> Moderating variables are added last, i.e.&nbsp;after main effects variables and control variables.</p></li>
</ol>
<p>In the field of Social Sciences, it is rare not to find control variables and/or moderators in multiple regressions because the social phenomena we tend to investigate are usually affected by other factors as well. Classic control variables or moderators are socio-demographic variables, such as age and gender. The following two chapters cover control variables and moderation effects separately from each other. However, it is not unusual to find both types of variables in the same regression model. Thus, they are not mutually exclusive approaches but simply different types of independent variables.</p>
<section id="sec-regressions-with-control-variables" class="level3" data-number="13.3.1">
<h3 data-number="13.3.1" class="anchored" data-anchor-id="sec-regressions-with-control-variables"><span class="header-section-number">13.3.1</span> Regressions with control variables</h3>
<p>Hierarchical regression implies that we add variables step-by-step, or as some call it, <em>‘block-wise’</em>. Each block represents a group of variables. Control variables tend to be the first block of variables added to a regression model. However, there are many other ways to perform multiple regression, for example, starting with all variables and removing those that are not significant, which <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> calls a ‘tear-down’ approach (p.&nbsp;158). As the title indicates, we take less of an exploratory approach to our analysis because we define the hierarchy, i.e.&nbsp;the order, in which we enter variables. In the Social Sciences, this is often the preferred method, so I cover it in greater detail.</p>
<p>However, I should probably explain what the purpose of entering variables in a stepwise approach is. As we discussed in the previous chapter, we sometimes face issues of multicollinearity, which makes it difficult to understand which variables are more important than others in our model. Therefore, we can decide to enter variables that we want to control first and then create another model containing all variables. The procedure is relatively straightforward for our research focus when predicting <code>new_cases</code> of COVID-19:</p>
<ol type="1">
<li>Create a model <code>m1</code> (or whatever name you want to give it) containing the dependent variable <code>new_cases</code> and a control variable, for example <code>country</code>.</li>
<li>Inspect the results of this model and note down the performance measures.</li>
<li>Create another model <code>m2</code> and include the control variable <code>country</code> and all other independent variables of interest, i.e.&nbsp;<code>schools</code>, and <code>businesses</code>.</li>
<li>Inspect the results of this model and note down the performance measures.</li>
<li>Compare models <code>m1</code> and <code>m2</code> to see whether they are significantly different from each other. We can use <code>anova()</code> to perform this step.</li>
</ol>
<p>Let’s put these steps into action and start with formulating our first model. I choose <code>country</code> as a control variable because we have sufficient evidence that clustered data could be a reason for the high autocorrelation of residuals we found in <a href="#sec-multicollinearity" class="quarto-xref"><span>Section 13.2.3</span></a>. For all computations in this section, we use the original dataset, i.e.&nbsp;<code>covid_uk_ger</code>, because we changed the model and therefore would have to revisit outliers from scratch, which we shall skip. We also have to remove observations with missing data to allow comparisons of models and ensure they have the same degrees of freedom (i.e.&nbsp;the same number of observations). So, we begin by selecting our variables of interest and then remove missing data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>hr_data <span class="ot">&lt;-</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>  covid_uk_ger <span class="sc">|&gt;</span></span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(new_cases, country, schools, businesses) <span class="sc">|&gt;</span></span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">droplevels</span>() <span class="sc">|&gt;</span></span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">na.omit</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We have to recode factors into so-called <a href="https://methods.sagepub.com/reference/the-sage-encyclopedia-of-educational-research-measurement-and-evaluation/i7682.xml?fromsearch=true" target="blank" title="dummy variables">dummy variables</a> or indicator variables. Dummy variables represent categories as <code>0</code>s (i.e.&nbsp;<code>FALSE</code> for this observation) and <code>1</code>s (<code>TRUE</code> for this observation). The good news is, the <code>lm()</code> function will do this automatically for us. If you want to inspect the coding ex-ante, you can use the function <code>contrasts().</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(hr_data<span class="sc">$</span>country)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               United Kingdom
Germany                     0
United Kingdom              1</code></pre>
</div>
</div>
<p>The column reflects the coding and the rows represent the levels of our factor. If we had more levels, we will find that the coding will always be the number of levels minus 1. This is a common mistake that novice analysts easily make. You might think you need to have a dummy variable for <code>Germany</code> (i.e.&nbsp;0 and 1) and a dummy variable for <code>United Kingdom</code> (i.e.&nbsp;0 and 1). However, all you really need is one variable, which tells us whether the <code>country</code> is the <code>United Kingdom</code> (i.e.&nbsp;1) or not (i.e.&nbsp;0).</p>
<p>If our control variable has more than two levels, for example, by adding <code>Italy</code>, the dummy coding will change to the following:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>hr_uk_ger_ita <span class="ot">&lt;-</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>  covid <span class="sc">|&gt;</span></span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(country <span class="sc">==</span> <span class="st">"United Kingdom"</span> <span class="sc">|</span></span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>           country <span class="sc">==</span> <span class="st">"Germany"</span> <span class="sc">|</span></span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>           country <span class="sc">==</span> <span class="st">"Italy"</span>) <span class="sc">|&gt;</span></span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">droplevels</span>()</span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(hr_uk_ger_ita<span class="sc">$</span>country)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               Italy United Kingdom
Germany            0              0
Italy              1              0
United Kingdom     0              1</code></pre>
</div>
</div>
<p>With this new dataset of three countries, our regression would include more control variables because we create a new control variable for each level of the factor (minus one level!).</p>
<p>Returning to our hierarchical regression, we can build our first model, i.e.&nbsp;<code>m1</code>, which only contains our control variable <code>country</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> new_cases <span class="sc">~</span> country,</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> hr_data)</span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">model_parameters</span>(m1, <span class="at">standardize =</span> <span class="st">"refit"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parameter                | Coefficient |   SE |         95% CI | t(1186) |      p
---------------------------------------------------------------------------------
(Intercept)              |       -0.18 | 0.04 | [-0.26, -0.10] |   -4.53 | &lt; .001
country [United Kingdom] |        0.37 | 0.06 | [ 0.25,  0.48] |    6.40 | &lt; .001</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed
  using a Wald t-distribution approximation.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">model_performance</span>(m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Indices of model performance

AIC       |      AICc |       BIC |    R2 | R2 (adj.) |      RMSE |     Sigma
-----------------------------------------------------------------------------
25542.724 | 25542.744 | 25557.964 | 0.033 |     0.033 | 11258.076 | 11267.564</code></pre>
</div>
</div>
<p>Our control variable turns out to be significant for our model, but it explains only a small proportion of the variance in <code>new_cases</code>. If you are testing hypotheses, you would consider this a good result because you do not want your control variables to explain too much variance. At the same time, it is a significant variable and should be retained in our model. Let’s construct our next model, <code>m1</code>, by adding the main effects variables and comparing our models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> new_cases <span class="sc">~</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>           schools <span class="sc">+</span></span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>           businesses <span class="sc">+</span></span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>           country,</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> hr_data)</span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">compare_parameters</span>(m1, m2, <span class="at">standardize =</span> <span class="st">"refit"</span>) <span class="sc">|&gt;</span></span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Parameter, Coefficient.m1, p.m1, Coefficient.m2, p.m2) <span class="sc">|&gt;</span></span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.double), round, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  Parameter                Coefficient.m1  p.m1 Coefficient.m2  p.m2
  &lt;chr&gt;                             &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;
1 (Intercept)                      -0.183     0         -0.235     0
2 country (United Kingdom)          0.365     0          0.469     0
3 schools                          NA        NA          0.328     0
4 businesses                       NA        NA          0.246     0</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">compare_performance</span>(m1, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Comparison of Model Performance Indices

Name | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) |    R2 | R2 (adj.) |      RMSE |     Sigma
--------------------------------------------------------------------------------------------------------------
m1   |    lm | 25542.7 (&lt;.001) | 25542.7 (&lt;.001) | 25558.0 (&lt;.001) | 0.033 |     0.033 | 11258.076 | 11267.564
m2   |    lm | 25234.1 (&gt;.999) | 25234.1 (&gt;.999) | 25259.5 (&gt;.999) | 0.257 |     0.255 |  9870.095 |  9886.753</code></pre>
</div>
</div>
<p>After adding all our variables, <span class="math inline">\(adjusted\ R^2\)</span> went up from <code>0.033</code> to <code>0.255</code>. While this might seem like a considerably improvement, we have to perform a statistical test to compare the two models. This leads us back to comparing groups, and in many ways, this is what we do here by using the function <code>anova()</code>, but we compare models based on the residual sum of squares, i.e.&nbsp;the amount of error the models produce. Thus, if the ANOVA returns a significant result, <code>m1</code> shows a significantly reduced residual sum of squares compared to <code>m2</code>. Therefore, <code>m2</code> would be the better model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m1, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: new_cases ~ country
Model 2: new_cases ~ schools + businesses + country
  Res.Df        RSS Df  Sum of Sq      F    Pr(&gt;F)    
1   1186 1.5057e+11                                   
2   1184 1.1573e+11  2 3.4839e+10 178.21 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The results confirm that our model significantly improved. You might argue that this is not surprising because we added those variables which already worked in the final model of <a href="#sec-multicollinearity" class="quarto-xref"><span>Section 13.2.3</span></a>. However, the important takeaway is that our control variable <code>country</code> helps us explain more variance in <code>new_cases</code>. Comparing the model with and without the control variable, we would find that the <span class="math inline">\(adjusted\ R^2\)</span> improves our model by about 25%. As such, it is worth keeping it as part of our final regression model. Here is evidence of this improvement:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>m0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> new_cases <span class="sc">~</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>           schools <span class="sc">+</span></span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>           businesses,</span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> hr_data)</span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-6"><a href="#cb130-6" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">compare_performance</span>(m0, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Comparison of Model Performance Indices

Name | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) |    R2 | R2 (adj.) |      RMSE |     Sigma
--------------------------------------------------------------------------------------------------------------
m0   |    lm | 25309.1 (&lt;.001) | 25309.2 (&lt;.001) | 25329.5 (&lt;.001) | 0.207 |     0.206 | 10195.397 | 10208.294
m2   |    lm | 25234.1 (&gt;.999) | 25234.1 (&gt;.999) | 25259.5 (&gt;.999) | 0.257 |     0.255 |  9870.095 |  9886.753</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m0, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: new_cases ~ schools + businesses
Model 2: new_cases ~ schools + businesses + country
  Res.Df        RSS Df  Sum of Sq      F    Pr(&gt;F)    
1   1185 1.2349e+11                                   
2   1184 1.1573e+11  1 7754483300 79.332 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>There are many more combinations of models we could test. For example, instead of specifying two models (<code>m1</code>, <code>m2</code>), we could also add independent variables one at a time and compare the resulting models to a baseline model (<code>m0</code>). Thus, we end up with more models to compare, for example:</p>
<div id="four-hierarchical-regressions-nested">
<p>m1 &lt;- lm(formula = new_cases ~ country, data = hr_data)</p>
<p>m2 &lt;- lm(formula = new_cases ~ country + schools, data = hr_data)</p>
<p>m3 &lt;- lm(formula = new_cases ~ country + schools + businesses, data = hr_data)</p>
</div>
<p>All these decisions have to be guided by the purpose of your research and whether you explore your data or have pre-defined hypotheses. However, the steps remain the same in terms of computation in <em>R</em>.</p>
</section>
<section id="sec-moderated-regression" class="level3" data-number="13.3.2">
<h3 data-number="13.3.2" class="anchored" data-anchor-id="sec-moderated-regression"><span class="header-section-number">13.3.2</span> Moderated regression</h3>
<p>While regressions with control variables help us decide whether to include or exclude variables by controlling for another variable, moderation models imply that we expect a certain interaction between an independent variable and a so-called moderator. A moderator also enters the equation on the right-hand side and therefore constitutes an independent variable, but it is usually entered after control variables and main effects variables.</p>
<p>In our quest to find a model that predicts new COVID cases, let’s assume that country is not a control variable but a moderating one. We could suspect that the measures for <code>businesses</code> and <code>schools</code> were significantly differently implemented in each country. Therefore, the strength of the relationship between <code>businesses</code>/<code>schools</code> and <code>new_cases</code> varies depending on the country. In other words, we could assume that measures showed different effectiveness in each of the countries.</p>
<p>When performing a moderation regression, we assume that the relationship between independent variables and the dependent variable differs based on a third variable, in our case, <code>country</code>. Thus, if we visualise the idea of moderation, we would plot the data against each other for each country separately and fit two (instead of one) regression lines by defining the colours of each group with <code>col = country</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the interaction between schools and country</span></span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>hr_data <span class="sc">|&gt;</span></span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> schools,</span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> new_cases,</span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">col =</span> country)) <span class="sc">+</span></span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> <span class="dv">5</span>,</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">size =</span> <span class="fl">0.5</span>,</span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb134-10"><a href="#cb134-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> x,</span>
<span id="cb134-11"><a href="#cb134-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-plotting-moderation-effects-schools" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plotting-moderation-effects-schools-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="13_regressions_files/figure-html/fig-plotting-moderation-effects-schools-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plotting-moderation-effects-schools-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.1: Plotting moderation effects for <code>schools</code>.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the interaction between schools and country</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>hr_data <span class="sc">|&gt;</span></span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> businesses,</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> new_cases,</span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">col =</span> country)) <span class="sc">+</span></span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> <span class="dv">5</span>,</span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">size =</span> <span class="fl">0.5</span>,</span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> x,</span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13_regressions_files/figure-html/plotting-moderation-effects-businesses-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Plotting moderation effects for <code>business</code>.</figcaption>
</figure>
</div>
</div>
</div>
<p>There are three interesting insights we can gain from these plots:</p>
<ol type="1">
<li>In terms of <code>business</code> measures, the <code>United Kingdom</code> seems to have more observations at the lower end, i.e.&nbsp;taking less protective measures than Germany. In contrast, for <code>schools</code>, it is the opposite.</li>
<li>For <code>schools</code>, the UK reports more frequently higher numbers of <code>new_cases</code> even if measures taken are high, which results in a steeper regression line.</li>
<li>However, for <code>businesses</code>, the <code>United Kingdom</code> had barely any <code>new_cases</code> when the measures were high, but Germany still reports high numbers of new cases when tight measures were taken.</li>
</ol>
<p>Given the difference in the slope of the regression lines, we have to assume that the <span class="math inline">\(\beta\)</span>s for <code>Germany</code> are quite different from the ones for the <code>United Kingdom</code>. It seems that the relationship between <code>new_cases</code> and <code>business</code>/<code>schools</code> can be partially explained by <code>country</code>. Therefore, we could include <code>country</code> as a moderator and introduce the interaction of these variables with each other into a new model, i.e.&nbsp;<code>m4</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> new_cases <span class="sc">~</span></span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>           schools <span class="sc">+</span></span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>           businesses <span class="sc">+</span></span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>           schools <span class="sc">*</span> country <span class="sc">+</span>  <span class="co"># moderator 1</span></span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>           businesses <span class="sc">*</span> country, <span class="co"># moderator 2</span></span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> hr_data)</span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-8"><a href="#cb136-8" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">compare_parameters</span>(m0, m4, <span class="at">standardize =</span> <span class="st">"refit"</span>) <span class="sc">|&gt;</span></span>
<span id="cb136-9"><a href="#cb136-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb136-10"><a href="#cb136-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Parameter, Coefficient.m0, p.m0, Coefficient.m4, p.m4) <span class="sc">|&gt;</span></span>
<span id="cb136-11"><a href="#cb136-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.double), round, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 5
  Parameter                            Coefficient.m0  p.m0 Coefficient.m4  p.m4
  &lt;chr&gt;                                         &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;
1 (Intercept)                                   0         1         -0.229 0    
2 schools                                       0.366     0          0.077 0.104
3 businesses                                    0.168     0          0.183 0    
4 country (United Kingdom)                     NA        NA          0.546 0    
5 schools × country (United Kingdom)           NA        NA          0.274 0    
6 businesses × country (United Kingdo…         NA        NA          0.371 0    </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">compare_performance</span>(m0, m4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Comparison of Model Performance Indices

Name | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) |    R2 | R2 (adj.) |      RMSE |     Sigma
--------------------------------------------------------------------------------------------------------------
m0   |    lm | 25309.1 (&lt;.001) | 25309.2 (&lt;.001) | 25329.5 (&lt;.001) | 0.207 |     0.206 | 10195.397 | 10208.294
m4   |    lm | 25149.9 (&gt;.999) | 25150.0 (&gt;.999) | 25185.5 (&gt;.999) | 0.310 |     0.307 |  9510.456 |  9534.564</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m0, m4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: new_cases ~ schools + businesses
Model 2: new_cases ~ schools + businesses + schools * country + businesses * 
    country
  Res.Df        RSS Df  Sum of Sq      F    Pr(&gt;F)    
1   1185 1.2349e+11                                   
2   1182 1.0745e+11  3 1.6035e+10 58.795 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The moderation effect is quite strong. Compared to our baseline model <code>m0</code>, which only contains <code>businesses</code> and <code>schools</code> as predictors, our new model <code>m4</code> considerably outperforms it with an <span class="math inline">\(adjusted\ R^2 = 0.307\)</span>. Our previous model with country as a control variable achieved an <span class="math inline">\(adjusted\ R^2 = 0.255\)</span>. I would argue this is quite an improvement.</p>
<p>While significant moderation effects help us make better predictions with our model, they come with a caveat: Interpreting the relative importance of the main effects becomes considerably more difficult because their impact depends on the level of our moderation variable. As such, you cannot interpret the main effects without considering the moderation variable as well. You might have noticed that our variable <code>schools</code> is not significant anymore. However, this does not imply it is not essential because its significance depends on the level of our moderator, i.e.&nbsp;whether we look at <code>Germany</code> or the <code>United Kingdom</code>.</p>
</section>
<section id="sec-centering-predictors" class="level3" data-number="13.3.3">
<h3 data-number="13.3.3" class="anchored" data-anchor-id="sec-centering-predictors"><span class="header-section-number">13.3.3</span> Centering predictors: Making <span class="math inline">\(\beta\)</span>s more interpretable</h3>
<p>In <a href="#sec-standardised-beta-vs-unstandardised-beta" class="quarto-xref"><span>Section 13.2.2</span></a>, we covered procedures to standardise <span class="math inline">\(\beta\)</span> coefficients, which allow us to compare independent variables based on different measurement units or if we want to compare coefficients across multiple models. Whenever we perform a regression with an interaction term, for example, the moderation regression in the previous chapter, we often have to make similar adjustments called <em>‘centering’</em>.</p>
<p>To explain why we might need centering, we should look at an example. Let’s consider a simple model using the <code>wvs_nona</code> dataset. Assume we want to know whether <code>freedom_of_choice</code> can predict <code>satisfaction</code> with life, moderated by <code>age</code>. If we formulate this as a model, we can write the following:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> satisfaction <span class="sc">~</span></span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>              freedom_of_choice <span class="sc">+</span></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>              freedom_of_choice <span class="sc">*</span> age,</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> wvs_nona)</span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">model_parameters</span>(model) <span class="sc">|&gt;</span></span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb142-8"><a href="#cb142-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Parameter, Coefficient, t, df_error, p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  Parameter             Coefficient      t df_error        p
  &lt;chr&gt;                       &lt;dbl&gt;  &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;
1 (Intercept)              3.42     16.3       8560 1.40e-58
2 freedom_of_choice        0.409    13.9       8560 1.50e-43
3 age                      0.00815   1.78      8560 7.57e- 2
4 freedom_of_choice:age   -0.000635 -0.978     8560 3.28e- 1</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">model_performance</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Indices of model performance

AIC       |      AICc |       BIC |    R2 | R2 (adj.) |  RMSE | Sigma
---------------------------------------------------------------------
37214.901 | 37214.908 | 37250.177 | 0.129 |     0.129 | 2.124 | 2.124</code></pre>
</div>
</div>
<p>The <span class="math inline">\(\beta\)</span> score of <code>freedom_of_choice</code> unfolds the most substantial effect on <code>satisfaction</code>, but assumes that <code>age = 0</code>. In regressions with interaction terms, the coefficient <span class="math inline">\(\beta\)</span> of a variable reflects the change in the dependent variables if other variables are set to zero. If this is a logical value for the variables, then no further steps are required. However, if a score of zero on any predictor is not meaningful, it is recommended to engage in centering variables <span class="citation" data-cites="cohen2014applied field2013discovering">(see <a href="references.html#ref-cohen2014applied" role="doc-biblioref">P. Cohen, West, and Aiken 2014</a>; <a href="references.html#ref-field2013discovering" role="doc-biblioref">Field 2013</a>)</span>. In our model, the coefficient of <code>freedom_of_choice</code> assumes that <code>age</code> is equal to <code>0</code>. However, no participant in our sample will have been of age <code>0</code>, which renders any interpretation of the <span class="math inline">\(\beta\)</span> coefficient meaningless. Instead, it is more meaningful to retrieve a <span class="math inline">\(\beta\)</span> score which is based on the average <code>age</code> of people in our sample. This is what centering can achieve.</p>
<p>There are mainly two very commonly used techniques in the Social Sciences to center variables: <em>grand mean centering</em> and <em>group mean centering</em>. The difference between these two approaches lies in their reference sample. For group mean centering, we compute means for each group independently and for grand mean centering, we calculate the mean for all observations irrespective of any groupings. Centered scores are almost the same as z-scores, but without using standard deviation as a measurement unit. If we divided centered scores by the standard deviation, we would have computed z-scores. The following formula summarises the computation of centered variables:</p>
<div id="centering-formula" data-align="center">
<p><span class="math inline">\(x_{n_{centered}} = x_n - \overline{x}\)</span></p>
</div>
<p>In other words, to achieve a centered variable (<span class="math inline">\(x_{n_{centered}}\)</span>), we have to take the original observation (<span class="math inline">\(x_n\)</span>) and subtract the mean of the variable (<span class="math inline">\(\bar{x}\)</span>). How we define <span class="math inline">\(\bar{x}\)</span> determines whether we perform grand mean centering (using the entire dataset) or group mean centering (using subsets of our data, i.e.&nbsp;groups). We already know all the functions needed to compute centered variables. Since the <code>age</code> of <code>0</code> is not meaningful in our study, we should center this variable around its mean<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Grand mean centering</span></span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>wvs_nona_c <span class="ot">&lt;-</span></span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>  wvs_nona <span class="sc">|&gt;</span></span>
<span id="cb146-4"><a href="#cb146-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">age_c =</span> age <span class="sc">-</span> <span class="fu">mean</span>(age))</span>
<span id="cb146-5"><a href="#cb146-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-6"><a href="#cb146-6" aria-hidden="true" tabindex="-1"></a>wvs_nona_c <span class="sc">|&gt;</span></span>
<span id="cb146-7"><a href="#cb146-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(age, age_c) <span class="sc">|&gt;</span></span>
<span id="cb146-8"><a href="#cb146-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
    age  age_c
  &lt;dbl&gt;  &lt;dbl&gt;
1    60  17.9 
2    40  -2.14
3    25 -17.1 
4    71  28.9 
5    38  -4.14
6    20 -22.1 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Group mean centering by country</span></span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>wvs_nona <span class="sc">|&gt;</span></span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(country) <span class="sc">|&gt;</span></span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">age_c =</span> age <span class="sc">-</span> <span class="fu">mean</span>(age)) <span class="sc">|&gt;</span></span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(age, age_c) <span class="sc">|&gt;</span></span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Adding missing grouping variables: `country`</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 3
# Groups:   country [6]
  country   age   age_c
  &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt;
1 Bolivia    28 -10.3  
2 Iran       48   8.52 
3 Iraq       27  -9.60 
4 Japan      81  26.2  
5 Korea      45  -0.630
6 Egypt      37  -2.70 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="do">## The group means used</span></span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>wvs_nona <span class="sc">|&gt;</span></span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(country) <span class="sc">|&gt;</span></span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean =</span> <span class="fu">round</span>(<span class="fu">mean</span>(age), <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
  country  mean
  &lt;fct&gt;   &lt;dbl&gt;
1 Bolivia    38
2 Iran       39
3 Iraq       37
4 Japan      55
5 Korea      46
6 Egypt      40</code></pre>
</div>
</div>
<p>The <code>mutate()</code> function is the same for both approaches. However, we used <code>group_by()</code> to compute the mean for each <code>country</code> and then centered the scores accordingly for group mean centering. Thus, observations from <code>Australia</code> will be centered around the mean score of <code>54</code>, while observations from <code>Myanmar</code> will be centered around the mean value of <code>40</code>.</p>
<p>Returning to our investigation, I opted to choose grand mean centering. Now we can use our newly centered variable in the regression to see the impact it had on our <span class="math inline">\(\beta\)</span>s.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>model_c <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> satisfaction <span class="sc">~</span></span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>                freedom_of_choice <span class="sc">+</span></span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a>                freedom_of_choice <span class="sc">*</span> age_c,</span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> wvs_nona_c)</span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-6"><a href="#cb153-6" aria-hidden="true" tabindex="-1"></a>parameters<span class="sc">::</span><span class="fu">compare_parameters</span>(model, model_c) <span class="sc">|&gt;</span></span>
<span id="cb153-7"><a href="#cb153-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb153-8"><a href="#cb153-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Parameter, Coefficient.model, p.model, Coefficient.model_c, p.model_c) <span class="sc">|&gt;</span></span>
<span id="cb153-9"><a href="#cb153-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.double), round, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 5
  Parameter              Coefficient.model p.model Coefficient.model_c p.model_c
  &lt;chr&gt;                              &lt;dbl&gt;   &lt;dbl&gt;               &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)                        3.42    0                   3.77      0    
2 freedom of choice                  0.409   0                   0.382     0    
3 age                                0.008   0.076              NA        NA    
4 freedom of choice × a…            -0.001   0.328              NA        NA    
5 age c                             NA      NA                   0.008     0.076
6 freedom of choice × a…            NA      NA                  -0.001     0.328</code></pre>
</div>
</div>
<p>In contrast to standardising the coefficients, it is not necessary to center all predictors in your dataset. For example, we only centered <code>age</code> and not <code>freedom_of_choice</code> in our case, because a value of <code>0</code> for the latter variable seems plausible. As we can tell from the output, the <span class="math inline">\(\beta\)</span> for <code>freedom_of_choice</code> has changed, but all other coefficients remained the same. In general, grand mean centering has the following effects:</p>
<ul>
<li><p>centering does not affect the <span class="math inline">\(\beta\)</span> of the centered variable (i.e.&nbsp;<code>age</code>), because we subtract a constant (i.e.&nbsp;the mean) from all observations equally,</p></li>
<li><p>centering does not affect the interaction term (i.e.&nbsp;<code>freedom_of_choice * age_c)</code>, which is also known as the ‘higher-order’ predictor,</p></li>
<li><p>centering changes the <span class="math inline">\(\beta\)</span> of the independent variable in the interaction term (also known as ’lower-order predictor), (i.e.&nbsp;<code>freedom_of_choice</code>)</p></li>
<li><p>centering does not change <span class="math inline">\(\beta\)</span>s of other variables that are not interacting with a centered variable.</p></li>
<li><p>centering any of the predictors changes the intercept.</p></li>
</ul>
<p>To conclude, centering plays a crucial role if the interpretation of <span class="math inline">\(\beta\)</span> coefficients is essential. If this is true, we should center all variables where a value of <code>0</code> is not meaningful. However, keep in mind that we do not change the model itself, i.e.&nbsp;we cannot improve the performance of a model by centering certain variables. Consequently, if we are only interested in the performance of our model, centering does not matter.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">compare_performance</span>(model, model_c)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Comparison of Model Performance Indices

Name    | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma
---------------------------------------------------------------------------------------------------------
model   |    lm | 37214.9 (0.500) | 37214.9 (0.500) | 37250.2 (0.500) | 0.129 |     0.129 | 2.124 | 2.124
model_c |    lm | 37214.9 (0.500) | 37214.9 (0.500) | 37250.2 (0.500) | 0.129 |     0.129 | 2.124 | 2.124</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-ols-alternatives" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="sec-ols-alternatives"><span class="header-section-number">13.4</span> Other regression models: Alternatives to OLS</h2>
<p>This book only covers linear regressions, which are considered <em>Ordinary Least Squares (OLS) regression</em> models. These are by far the most frequently used models in the Social Sciences. However, what can we do if the assumptions of OLS models are violated, for example, the relationship of variables looks curved or if our dependent variable is dichotomous and not continuous? In such cases, we might have to consider other types of regression models. There are several different approaches, but we most frequently find one of the following:</p>
<ul>
<li><p><em>Polynomial regressions</em>, which are used for curvilinear relationships between variables.</p></li>
<li><p><em>Generalised Linear models</em>, such as <em>Logistic regressions</em> (when the predictor is a logical variable) or <em>Poisson regressions</em> (when we model count data, i.e.&nbsp;frequencies and contingency tables).</p></li>
</ul>
<p>These are specialised models, and learning them requires a more in-depth knowledge of their mechanics which would go beyond the scope of a book that intends to cover the basics of conducting statistical analysis in <em>R</em>. However, <span class="citation" data-cites="cohen2014applied">P. Cohen, West, and Aiken (<a href="references.html#ref-cohen2014applied" role="doc-biblioref">2014</a>)</span> offers an excellent introduction to both approaches.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-boehmke2019hands" class="csl-entry" role="listitem">
Boehmke, Brad, and Brandon Greenwell. 2019. <em>Hands-on Machine Learning with r</em>. Chapman; Hall/CRC.
</div>
<div id="ref-cohen1988statistical" class="csl-entry" role="listitem">
Cohen, Jacob. 1988. <em>Statistical Power Analysis for the Behavioral Sciences New York</em>. <em>NY: Academic Press</em>.
</div>
<div id="ref-cohen2014applied" class="csl-entry" role="listitem">
Cohen, Patricia, Stephen G West, and Leona S Aiken. 2014. <em>Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences</em>. Psychology press.
</div>
<div id="ref-cook1982residuals" class="csl-entry" role="listitem">
Cook, R Dennis, and Sanford Weisberg. 1982. <em>Residuals and Influence in Regression</em>. New York: Chapman; Hall.
</div>
<div id="ref-field2013discovering" class="csl-entry" role="listitem">
Field, Andy. 2013. <em>Discovering Statistics Using IBM SPSS Statistics</em>. Sage Publications.
</div>
<div id="ref-gelman2020regression" class="csl-entry" role="listitem">
Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. <em>Regression and Other Stories</em>. Cambridge University Press.
</div>
<div id="ref-sage-methods2004dbw" class="csl-entry" role="listitem">
Grandstrand, Ove. 2004. <span>“Durbin-Watson Statistic.”</span> In <em>The SAGE Encyclopedia of Social Science Research Methods</em>, edited by Bryman Lewis-Beck Michael S. Thousand Oaks, California. <a href="https://methods.sagepub.com/reference/the-sage-encyclopedia-of-social-science-research-methods">https://methods.sagepub.com/reference/the-sage-encyclopedia-of-social-science-research-methods</a>.
</div>
<div id="ref-hoaglin1978hat" class="csl-entry" role="listitem">
Hoaglin, David C, and Roy E Welsch. 1978. <span>“The Hat Matrix in Regression and ANOVA.”</span> <em>The American Statistician</em> 32 (1): 17–22.
</div>
<div id="ref-stevens2012applied" class="csl-entry" role="listitem">
Stevens, James P. 2012. <em>Applied Multivariate Statistics for the Social Sciences</em>. Routledge.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Germany is called ‘Deutschland’ in German, hence the abbreviation ‘DEU’ according to the <a href="https://www.iso.org/obp/ui/#iso:code:3166:DE" target="blank" title="ISO country code">ISO country code</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Be aware that such insights might also fundamentally question the relationship between variables, i.e.&nbsp;are the measures truly independent variables or rather dependent ones?<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>This function does not take the model as an attribute, but instead requires the data, the column means and the covariance. Thus, we have to specify this function in the following way: <code>mahalanobis(data, colMeans(data), cov(data))</code><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Function from <code>rstatix</code> package which automatically classifies values as outliers for us.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>It is not required to choose the mean as a way to center variables. Any value that is meaningful can be used. However, the mean often tends to be the most meaningful value to perform centering.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./12_power_analysis.html" class="pagination-link  aria-label=" &lt;span="" you="" either="" have="" it="" or="" don&#39;t&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Power: You either have it or you don’t</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./14_mixed_methods.html" class="pagination-link" aria-label="<span class='chapter-number'>14</span>&nbsp; <span class='chapter-title'>Mixed-methods research: Analysing qualitative data in *R*</span>">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Mixed-methods research: Analysing qualitative data in <em>R</em></span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ddauber/r4np-quarto-crc/blob/main/13_regressions.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/ddauber/r4np-quarto-crc/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>